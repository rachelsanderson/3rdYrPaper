\documentclass[12pt]{article}
\usepackage[margin=0.1in]{geometry}
%\usepackage[nomarkers,nofiglist,notablist]{endfloat}
\usepackage{xcolor}
\usepackage{framed}
\usepackage{enumitem}
\usepackage{adjustbox}
\usepackage{natbib}
\usepackage{chngpage}
\usepackage{mathtools,xparse}
\usepackage{graphics}
\usepackage{tikz}
\usepackage{tabu}
\usepackage{tikz-cd}
\colorlet{shadecolor}{orange!15}
% \definecolor{shadecolor}{rgb}{255,128,0}\
\usepackage{float}
\usepackage{fullpage} % Package to use full page
\usepackage{parskip} % Package to tweak paragraph skipping
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{hyperref}
\usepackage{pdflscape}
\usepackage{setspace}
\usepackage{graphicx} % Allows including images
\usepackage{booktabs} % Allows the use of \toprule, \midrule and \bottomrule in tables
\usepackage{longtable}
\usepackage{indentfirst}
\usetikzlibrary{arrows,shapes,positioning,shadows,trees}
\usepackage{array}
\usepackage{wrapfig}
\usepackage{multirow}
\usepackage{pdflscape}
\usepackage{threeparttable}
\usepackage{makecell}
\usepackage[normalem]{ulem}
\newcommand{\PreserveBackslash}[1]{\let\temp=\\#1\let\\=\temp}
\newcolumntype{L}[1]{>{\PreserveBackslash\raggedright}m{#1}}
\newcolumntype{R}[1]{>{\PreserveBackslash}p{#1}}
\newcolumntype{C}[1]{>{\PreserveBackslash\centering}m{#1}}
\newcommand{\Var}[1]{\text{Var}\left(#1\right)}
\newcommand{\mc}[3]{\multicolumn{#1}{#2}{#3}}

\tikzset{
  basic/.style  = {draw, text width=2cm, drop shadow, font=\sffamily, rectangle},
  root/.style   = {basic, rounded corners=2pt, thin, align=center,
                   fill=green!30},
  level 2/.style = {basic, rounded corners=6pt, thin,align=center, fill=green!60,
                   text width=8em},
  level 3/.style = {basic, thin, align=left, fill=pink!60, text width=6.5em}
}


\newcommand\independent{\protect\mathpalette{\protect\independenT}{\perp}}
\newcommand\gamij{\mathbf{\gamma_{ij}}}
\def\independenT#1#2{\mathrel{\rlap{$#1#2$}\mkern2mu{#1#2}}}
\newcommand\params{(p_M, p_{M\ell}, p_{U\ell})}
\newcommand\longparam{(L,n_1,n_2, p_M,p_{M\ell},p_{U\ell})}


%Allows multi-column tables 
\input{./Deadlines/tcilatex}

\setlength{\topmargin}{-0.4in} 
\setlength{\textheight}{8.9in}
\setlength{\parindent}{2em}
\setstretch{1.5}

\title{\singlespacing Methods for analyzing linked data}
\author{Rachel Anderson\thanks{Mailing Address: Department of Economics, Julis Romo Rabinowitz Building,
Princeton, NJ 08544. Email: rachelsa@princeton.edu.  I am grateful to Bo Honor\'e for guidance on this project, and to Melissa Plotsky and Bryan Anderson for their expert copy editing.  This project received funding from the NIH (Grant 1 R01 HD077227-01). }}
\date{This Version: \today}

\begin{document}

\maketitle

\begin{abstract}
\singlespacing
\noindent This paper compares methods for estimating linear regression models when the variables of interest are recorded in separate datasets that must be merged prior to analysis.  When it is not possible to identify the true matches with certainty, random errors in matching cause standard estimators to be biased \citep*{NeterMaynes}.  
In this context, \cite{sw1993} and \cite*{ahl2019} propose methods to correct for the bias, however each procedure requires distinct assumptions on how the data are linked.  This paper establishes conditions under which these methods are equivalent, and compares their performance using data that are matched by different record linkage procedures.  The results suggest that the estimator from \citet*{ahl2019} is unbiased under weaker assumptions, and without sacrificing efficiency.  The paper concludes with practical suggestions for analyzing linked data and discusses future areas of theoretical study. \end{abstract}
\newpage

\section{Introduction}

When analyzing multiple data sources with overlapping units, automated record linkage procedures offer a computationally efficient solution for merging data.  These methods allow the researcher to specify a set of matching variables and a decision rule for linking observations to obtain a matched dataset in a matter of minutes.  If the files to be linked are large, the time saved relative to manual linking or automated linking with clerical review is immense. 

In the social sciences, interest in automated record linkage methods has emerged in response to the increasing availability of administrative datasets, including recently digitized historical complete count population censuses.  These data often contain identifiers that are prone to typographical, duplication, enumeration, and mis-reporting errors.  Although methods for record linkage in this context have been developed in statistics, computer science, operations research, and epidemiology, economic historians and historical demographers have developed their own linking algorithms out of concern about the accuracy and representativeness of data that are matched using imperfect identifiers \citep*{ferrie96, abe2012, abe2014, abe2019b}.

Recent papers by \citet*{abe2019} and \citet*{bailey2017} compare the performance of popular historical record linkage methods to datasets matched by hand-linking or to simulated ``ground truth" datasets.  Although they implement different methods, both papers document a tradeoff between the false positive rate and the (true) match rate across procedures, and seem to agree that using more conservative algorithms leads to more representative data.  

Other contributions to this literature include papers by \citet*{arp2018} and \citet*{enamorado2019}, who demonstrate how to apply probabilistic record linkage methods from statistics to match historical and large-scale survey data.  These methods offer an advantage over the deterministic methods studied by \citet*{abe2019} and \citet*{bailey2017}, in that they can quantify the uncertainty about the matched data.  Furthermore, this extra information can be used to correct for bias introduced by false matches in the Ordinary Least Squares (OLS) estimator, using methods proposed by \cite{sw1993} and \citet*{lahiri05}.

The ability to use probabilistic record linkage to correct for bias in the OLS estimator illustrates how the \textit{outputs} of different matching procedures determine which estimation methods are available for subsequent analysis.  Similarly, \citet*{ahl2019} develop methods for consistently estimating Generalized Method of Moments (GMM) models using linked data that include multiple matches per observation.  Unfortunately, none of these estimation methods is acknowledged in the survey papers by \citet*{abe2019} and \citet*{bailey2017}; however, it seems natural that the choice of which matching procedure to use should be informed by which estimation methods are available. 

% good til here


%Whereas the former relies on data that are linked probabilistically, the latter assumes that observations are linked to multiple possible matches, and is unbiased as long as the true match is included in the set of matches.  
%However, \cite{sw1993} show how to correct for the bias if the datasets are matched using probabilistic record linkage methods; and \citet*{ahl2019} propose an estimator that is unbiased as long as true match is included among an observation's possible matches.  This paper establishes conditions under which these methods are equivalent, and compares their performance using matched data that is linked with different record linkage procedures.   \end{abstract} 



The goal of this paper is therefore to connect the existing literature on matching and estimating linear regression models with linked data.  I compare the performance of different methods that incorporate different types of information, as well as extend the methods from \citet*{ahl2019} to incorporate probabilities as may be outputted from a record linkage procedure.  Using these estimation methods for a variety of matched datasets, that are obtained by applying different matching procedures on the same raw data, allows me to conclude which \textit{combinations} of matching and estimation procedures perform best in practice.  The theoretical and empirical analyses in this paper suggest that deterministic matching methods which allow for multiple links, combined with the estimator from \citet*{ahl2019}, may be a promising method for increasing the match rate, without introducing bias or sacrificing efficiency if the sample size is sufficiently large.  

The rest of this paper is laid out as follows.  Section 2 describes a simplified version of the setup from \citet*{ahl2019}, which I call the linked data regression problem.  Section 3 describes two existing methods for estimating linear regression models with matched data -- specifically, the estimators proposed by \cite{sw1993} and \citet*{ahl2019} -- and describes under what conditions they are equivalent.  Section 4 explores how knowledge of match probabilities may be used to improve the efficiency of the estimator from \citet*{ahl2019}.   Section 5 describes in detail how I test these methods in a Monte Carlo study that involves simulating and linking datasets with a variety of record linkage techniques, Section 6 reports the results, and Section 7 concludes. 

% maybe add to intro Other methods for estimating with linked data are ad hoc or are not easily adapted to the setup in Section 2.  For example, \cite{bleakley2016} generated ``composite match" equal to the average of the linked observations.   \cite{nq2015} construct bounds on the parameter of interest using different configurations of matched data.   \cite{abe2012} use traditional estimation methods using only individuals who are uniquely matched, and then reweight on observables (not sure what this means?).   In statistics, authors have suggested using probabilistic record linkage and multiple imputation to correct for bias introduced by errors in the matching process \cite{sw1993, lahiri05, Goldstein2012}.   Multiple imputation is not useful here, as we do not consider missing data. The Lahiri methods require $N_x = N_y$ and so we are left with two methods.

%Each step of the record linkage process introduces the possibility that a true match is overlooked (Type II error), or that a false match is designated as correct (Type I error); and, generally, there is a tradeoff between reducing either one of the two \citep{abe2019, harron2018}.  Also representativeness is an issue. However, the impact of data pre-processing choices on estimation is still not well understood.  

%discussion can include where this may fail. 
%The example of \cite{aizer2016} illustrates how the choice of matching procedure determines which estimation methods are available.  Alternatively, the authors could have used probabilistic record linkage to estimate the probability that a given $(x_i, y_j)$ pair refers to a match, and incorporated this information into their estimation using the methods described in \cite{sw1993}.  

\section{Setup} 

In this section, I describe a simplified version of the estimation problem described in \citet*{ahl2019}.  Here, the goal is to estimate $\beta$ in the linear regression model, \begin{equation} y_i = x_i'\beta + \varepsilon_i, \ E[\varepsilon_i | x_i] = 0, \ E[\varepsilon_i^2 | x_i ] = \sigma^2  \label{model} \end{equation}
and I consider estimation techniques based on the following assumptions. 

\addlinespace
\textbf{Assumption 1.}  The variables of interest are $x_i$ and $y_j$, which are recorded in separate datafiles, along with the sets of identifiers $w_i$ and $w_j$.  Formally, the raw data consist of an $x$-datafile with observations $\{x_i, w_i\}_{i=1}^{N_x}$, and a $y$-datafile with observations $\{y_j, w_j\}_{j=1}^{N_y}$.   I assume that $N_y\geq N_x$, and that every $x_i$ has a corresponding value in the $y$-datafile that generates the relationship in (\ref{model}), but the identity of this match is unknown.  Furthermore, some $y_j$ may not correspond to any value in the $x$-datafile, so that estimation requires identifying which $(x_i,y_j)$ pairs refer to the same individuals.
\addlinespace
\textbf{Example 1.}  To fix ideas, consider the work of \citet*{aizer2016}, who seek to estimate the impact of providing cash transfers to single mothers on the life expectancy of their children.  The $x$-datafile consists of mothers' welfare program applications, where $x_i$ includes a binary variable equal to 1 if person $i$'s mother received a cash transfer, and other demographic variables.  The $y$-datafile is a universal database of death records, which includes $y_j$, person $j$'s age at death for all deaths reported to the Social Security Administration after 1965.  Both of the $x$- and $y$-datafiles also contain identifiers $w_i$ and $w_j$, which include first name, middle initial, last name, day, month, and year of birth, so that individuals with common names may not be identified uniquely. 
\addlinespace

\textbf{Assumption 2.}  The raw data are linked using $w_i$ and $w_j$, resulting in a matched dataset of the form,
\begin{equation} \mathcal{D}_n \equiv \left(x_i, w_i, \{y_{i\ell}\}_{\ell=1}^{L_i}, \{\pi_{i\ell}\}_{\ell=1}^{L_i}\right)_{i=1}^N \label{data} \end{equation}
so that some values of $x_i$ may be linked to multiple possible matches $\{y_{i\ell}\}_{\ell=1}^{L_i}$, and $\{\pi_{i\ell}\}_{\ell=1}^{L_i}$ is a vector of (estimated) probabilities that reflects how likely each of the $y_{i\ell}$ is to be the true match.  Also, because $N_x \geq N$ and $L_i$ is free to vary across $i$, I assume that $\{y_{i\ell}\}_{\ell=1}^{L_i}$ includes the unique true match for all of the observations in $\mathcal{D}_n$.  

\addlinespace
\textbf{Example 1 (cont'd).} \citet*{aizer2016} link observations using a deterministic method that accounts for potential errors in $w_i$ and $w_j$.  To account for changes in spelling and typographical errors, they convert all names into sounds using a phonetic algorithm, and measure the similarity between two individual's phonetically-spelled names using a string distance metric called SPEDIS \citep{spedis}.  They assign as matches all pairs of individuals whose SPEDIS scores and differences in birthdates fall within a pre-specified range.  Their procedure does not enforce unique matches, so some individuals with common names are matched to multiple death records.
\addlinespace

\textbf{Assumption 3.} The observations of $x_i$ and $\{y_{i\ell}\}_{\ell=1}^{L_i}$ included in $\mathcal{D}_n$ comprise random samples conditional on the identifying variables $w_i$.  More specifically, I assume that each $x_i$ is drawn independently from $f_x(x | w_i)$, and its true match $y_i$ is drawn from $f_y(y | x_i, w_i)$; and, the false matches $y_j$ are drawn independently from $f_y(y | w_j)$.   

\addlinespace
\textbf{Example 1 (cont'd)}.  Assumption 3 requires that all individuals with the same identifying information are equally likely to be included in $\mathcal{D}_n$.  This would be violated if, for example, higher income individuals had a greater probability of appearing in the sample, unless $w_i$ and $w_j$ were to include or proxy for income.  Importantly, Assumption 3 does not rule out all forms of selection, as $w_i$ could be correlated with selection into $\mathcal{D}_n$.  This could occur if individuals with some names were easier (or harder) to match, and may pose additional challenges for analysis that are beyond the scope of this paper. 

\section{Estimation methods for linked data }

In this section, I review methods from \cite{sw1993} and \citet*{ahl2019} for estimating regression models using matched data, and establish conditions under which they are equivalent.   Although there are other methods for analyzing linked data, such as those proposed by \citet*{lahiri05} and \citet*{Goldstein2012}, they assume that each observation in the $y$-datafile has a unique match in the $x$-datafile, which is violated if $N_y > N_x$.  Furthermore, the setup in Section 2 is more general than those considered previously, because it does not assume that all of the observations in the $y$-datafile are generated according to (\ref{model}).  

\subsection{\cite{sw1993}}

Building upon the work \citet*{NeterMaynes}, \cite{sw1993} demonstrate how to correct for bias introduced using incorrectly linked data in linear regression models.  Their methods assume that the data consist of observations $(x_i,z_i)_{i=1}^N$, so that each $x_i$ is linked with a single outcome $z_i$ that may or may not correspond to the true $y_i$.  Specifically, 
$$z_i = \begin{cases} y_i & \text{with probability $q_{ii}$} \\ y_j & \text{with probability $q_{ij}$ for $j\neq i,\ j = 1,\dots,N_y $} \end{cases}$$ 
and $\sum_{j=1}^{N_y} q_{ij} = 1, \ i=1,\dots, N$, where $N_y$ is the size of the $y$-datafile and $N$ is the size of the matched dataset.   Estimating (\ref{model}) using $z_i$ as the dependent variable yields the naive least squares estimator, 
\begin{equation} \hat{\beta}_N = (X'X)^{-1} X'z \label{naive} \end{equation}
which is inconsistent, because $ E[z_i ] = E\left[q_{ii} y_i + \sum_{j\neq i} q_{ij} y_j\right] \neq E[y_i]$ if $q_{ii}\neq 1$ for some $i$.  Denoting
 $q_i = (q_{i1}, \dots, q_{iN_y})'$, \cite{sw1993} derive the bias of $\hat{\beta}_N $ conditional on the observed values of $y$,
\begin{equation} \text{bias} (\hat{\beta}_N | y) = E[(\hat{\beta}_N - \beta) | y ] = (X'X)^{-1} X'B \label{bias} \end{equation}
where $B = (B_1, \dots, B_n)'$ and $B_i = (q_{ii}-1)y_i + \sum_{j\neq i } q_{ij} y_j = q_i'y - y_i$, which is the difference between a weighted average of responses from all observations and the true response $y_i$.  

Observing (\ref{bias}), \cite{sw1993} propose estimating $\hat{B}$ using the first and second highest elements of $q_i$, and their corresponding values $y_j$ to compute 
\begin{equation} \hat{B}_i^{TR} = (q_{ij_1} - 1) y_{ij_1} + q_{ij_2} y_{ij_2} \label{bHat} \end{equation}
for each $i$, and then using it to correct for the bias in $\hat{\beta}_N$ as follows,
\begin{equation} \hat{\beta}_{SW} = \hat{\beta}_N - (X'X)^{-1} X' \hat{B}^{TR} \label{sw}\end{equation}
which I henceforth refer to as the SW estimator.  In principle, $\hat{B}^{TR}$ can incorporate any number of elements of $q_i$, however \cite{sw1993} show that if $q_{ij1}$ is sufficiently high for all $i$, then the truncation with two links results in a very small bias.  
 
In addition to Assumptions 1-3, the SW estimator imposes two additional assumptions that complicate its implementation.  The first is that the $y$ value associated with the largest element in $q_i$ corresponds with the true outcome $y_i$, so that errors in $z_i$ result from random assignment rules or requiring that no two values $x_i$ and $x_j$ are linked to the same value of $y$.  The second is that constructing $\hat{\beta}_{SW}$ requires knowledge of $q_{i}$ and the corresponding elements of $y$, which may not be available for data linked with deterministic methods.  Even if estimates of $q_{ij}$ are available, $\hat{\beta}_{SW}$ will be biased if the estimates $\widehat{q_{ij}}$ are correlated with $x$ or $y$, which occurs if $x$ or $y$ is correlated with errors in the matching variables.  This assumption may fail in settings such as \cite{nq2015}, where $y$ measures whether a person's recorded ethnicity changes between Census years, and changes in first and last name (the matching variables) are strongly correlated with $y$.  

\subsection{\citet*{ahl2019}}

\citet*{ahl2019} consider estimating $\theta_0$ that satisfies the model
\begin{equation}
E_0\left[ m\left( y_{i},x_{i};\theta _{0}\right) \right] =0
\label{Moment}
\end{equation}%
where $y_{i}$ and $x_{i}$ are vectors or scalars of data for an individual $i$, the function $m(\cdot)$ is known, and the expectation is taken with respect to the joint distribution $f_0(y,x)$.  The data consist of observations $\left(x_i, w_i, \{y_{i\ell}\}_{\ell=1}^{L_i}\right)_{i=1}^N$, where the $x_i$ and $y_{i\ell}$ are recorded in distinct datasets and matched according to the identifier $w_i$.  They assume $L_i > 1$ for some $i$, so that the identity of the outcome that generates the relationship in (\ref{Moment}) is unknown.  

Under Assumptions 1-3, (\ref{Moment}) can be rewritten,
\begin{gather*}
E_0[m(y_i, x_i; \theta)] = E\left[\sum_{\ell=1}^{L_i} m(y_{i\ell}, x_i; \theta)\right] - E\left[(L_i -1)g(w_i, L_i; x_i; \theta)\right] \\ 
g(w_i, L_i, x_i; \theta) = E\left[m(y_i, x_i; \theta) |\ w_i, L_i \right] 
\end{gather*}
so if $g$ is known or can be estimated consistently, a sample version of (\ref{Moment}) can be constructed as follows,
\begin{equation}
\overline{m}_n(\theta, \hat{g}) = \frac{1}{N}\sum_{i=1}^N \sum_{\ell=1}^{L_i} m(y_{i\ell}, x_i ;\theta) - \frac{1}{N}\sum_{i=1}^N (L_i-1) \hat{g}(w_i, L_i, x_i; \theta) 
\label{ahl_moment}
\end{equation}
which is in general a two-step procedure, where $\hat{g}$ is estimated using nonparametric methods such as $k$-Nearest Neighbors or local polynomial regression in the first step.  The GMM estimator applied to (\ref{ahl_moment}) is consistent and asymptotically normal under the regularity conditions described in \citet*{ahl2019}. 

Applied to the linear regression model in (\ref{model}), the procedure above is equivalent to applying OLS to the transformed regression model, 
\begin{equation} 
\sum_{\ell=1}^{L_i} y_{i\ell} - (L_i - 1)\hat{g}(w_i, L_i) = x_i'\beta + u_i  \label{ahl} \end{equation}
where $\hat{g}(w_i,L_i)$ is a (possibly nonparametric) estimator of $E[y_{i\ell} | w_i, L_i ]$, $u_i = \varepsilon_i + \sum_{\ell=1}^{L_i}\nu_{i\ell}$, and $\nu_{i\ell} = y_{i\ell} - \hat{g}(w_i, L_i)$.   If, additionally, $E[\varepsilon_i^2 | x_i, w_i, L_i] = \sigma_{\varepsilon}^2$ and $E[\nu_{i\ell}^2 | x_i, w_i, L_i] = \sigma_{\nu}^2$ then the efficient estimator is weighted least squares,
\begin{equation}
\hat{\beta}^{AHL} = \left(\sum_{i=1}^N \frac{x_ix_i'}{\sigma(X_i)}\right)^{-1}\left(\sum_{i=1}^N \frac{x_i}{\sigma(X_i)}\left(\sum_{\ell=1}^{L_i} y_{i\ell} - (L_i - 1) g(w_i, L_i)\right)\right) \label{wls}
\end{equation}
where $\sigma(X_i) = \sigma_{\varepsilon}^2 + (L_i - 1)\sigma_{\nu}^2$.  I henceforth refer to (\ref{wls}) as the AHL estimator. 

Unfortunately, the performance of the AHL estimator depends on the accuracy of $\hat{g}(w_i, L_i)$, which is a function of a potentially high-dimensional vector $w_i$ that may contain string or categorical variables.  However, if we consider adding another assumption that $E_0[m(y_i, x_i; \theta) | L_i = \ell] = E_0[m(y_i, x_i; \theta)]$, then we could construct the moments, 
\begin{equation}
E_0[m(y_i, x_i; \theta)] = E\left[\sum_{\ell=1}^{L_i} m(y_{i\ell}, x_i; \theta) \Bigg|\ L_i = 2 \right]  - E\left[ \sum_{\ell=1}^{L_i} m(y_{i\ell}, x_i; \theta) \Bigg|\ L_i = 3\right] \label{new_ahl} \end{equation}
and
\begin{equation}
E_0[m(y_i, x_i; \theta)] = E[m(y_{i\ell}, x_i; \theta) | L_i =1]  \label{obs}
\end{equation}
and apply GMM to (\ref{new_ahl}) and (\ref{obs}) as the new moment conditions.   In practice, the precision of the estimator depends on the number of observations that are linked to two and three outcomes.  Additional work is necessary to evaluate the theoretical performance and feasibility of this estimator.  

\subsection{Comparing $\hat{\beta}_{SW}$ and $\hat{\beta}_{AHL}$}
There is a natural parallel between $\hat{\beta}_{SW}$ and $\hat{\beta}_{AHL}$ when we consider data of the form in (\ref{data}), and we assume that $L_i$ is the number of links whose $q_{ij}$ exceed a threshold $\bar{q}$, and that the conditional probabilities $\pi_{i\ell} = \frac{q_{i\ell}}{\sum_{\ell=1}^{L_{i}} q_{i\ell}}$.  Let also $y_{i\ell^*}$ refer to the element of $\{y_{i\ell}\}_{\ell=1}^{L_i}$ that is associated with the highest value of $\{\pi_{i\ell}\}_{\ell=1}^{L_i}$.  Then, we can write $\hat{\beta}_{SW}$ as the OLS estimator for the model
\begin{equation}
z_i - \hat{B}_i = x_i'\beta + \varepsilon_i 
\label{transformed}
\end{equation}
with $\hat{B}_i = \sum_{\ell =1}^{L_i} \pi_{i\ell} y_{i\ell} - y_{i\ell^*}$.  

The AHL estimator can be written in the form (\ref{transformed}) with 
\begin{equation}
\hat{B}_i = z_i - \sum_{\ell=1}^{L_i} y_{i\ell} + (L_i -1) \hat{g}(w_i, L_i) \end{equation} 
so that $\hat{\beta}^{AHL}$ and $\hat{\beta}^{SW}$ differ only in their choice of $B_i$.  Alternatively, $\hat{\beta}_{SW}$ can be written in the form of $\hat{\beta}_{AHL}$, by setting 
\begin{equation} \hat{g}(w_i, L_i) = \frac{1}{L_i -1 }\left( \sum_{\ell \neq \ell^*} y_{i\ell} + y_{i\ell^*} \right) \label{ahl_sw_eq} \end{equation}
Since $\hat{g}(\cdot)$ as written in (\ref{ahl_sw_eq}) ignores information about $w_i$, and assumes that $y_{i\ell^*}$ is the correct match, the AHL estimator may perform better if $y_{i\ell^*}$ is not the true match, informative $\pi_{i\ell}$ are not available, or $w_i$ contains information about the conditional mean of the $y_{i\ell}$ drawn from the incorrect distribution.   However, if reliable estimates of $\pi_{i\ell}$ are available, it may be possible to improve the AHL estimator by incorporating this information.  I explore this possibility in the next section. 

\section{Incorporating probabilities in the AHL estimator} 

I begin by considering a simplified version of the problem in \citet*{ahl2019}, based on the observation that 
$$ E[m(y_{i\ell}, x_i; \theta)] =  \begin{cases} 0 & \text{if } y_{i\ell} = y_i \\
g(w_i, L_i, x_i; \theta) & \text{if } y_{i\ell} \neq y_i
\end{cases} $$
If $\hat{g}$ can be estimated consistently, or $g(\cdot)$ is a constant function, this problem can be reduced to estimating the mean using observations $\{X_{i\ell}\}_{\ell=1}^{L_i}$, where each $X_{i\ell}$ is drawn from the correct distribution with probability $\pi_{i\ell}$ and drawn from the incorrect distribution with probability $(1-\pi_{i\ell})$.  Under Assumption 2, exactly one of the $X_{i\ell}$ is drawn from the correct distribution, so that $\sum_{\ell=1}^{L_i} X_{i\ell} = \mu + (L_i -1) \kappa$, where $\mu =0$ in the above example, and $\kappa = g(\cdot)$. 

\subsection{Estimating the mean}

Consider the problem of estimating the mean of a random variable $X \sim F_X(\mu; \sigma^2)$ using two observations $X_{1}$ and $X_{2}$.  With probability $\pi$, $X_1$ is drawn from the true distribution $F_X$ and $X_2$ is noise drawn from the distribution $F_Y(\kappa, \omega^2)$.  With probability $1-\pi$, $X_2$ is drawn from the correct distribution and $X_1$ is noise.  Under this specification, exactly one of $X_1$ or $X_2$ is drawn from the distribution of interest at all times.  

Observe that if $\pi$ is known, we can construct an unbiased estimator using only $X_1$,
\begin{equation}
\hat{\mu}_1 = \frac{X_1}{\pi} - \frac{1-\pi}{\pi} \kappa 
\label{mu1}
\end{equation} 
and, similarly, we can construct an unbiased estimator using only $X_2$,
\begin{equation}\hat{\mu_2} = \frac{X_2}{1-\pi} - \frac{\pi}{1-\pi} \kappa \label{mu2} \end{equation} 
Any unbiased linear estimator $\hat{\mu}$ that uses both $X_1$ and $X_2$ can be written as a combination of $\hat{\mu}_1$ and $\hat{\mu}_2$ (see Lemma 1 in the Appendix for a proof), so finding the minimum variance, unbiased linear estimator $\hat{\mu}$ requires minimizing 
$$\min_d\  \Var{d \hat{\mu}_1 + (1-d) \hat{\mu}_2}$$
which is solved by \begin{equation} d^*= \frac{\Var{\hat{\mu}_2} - \text{Cov}(\hat{\mu}_1, \hat{\mu}_2)}{\Var{\hat{\mu}_1} + \Var{\hat{\mu}_2} - 2 \text{Cov}(\hat{\mu}_1, \hat{\mu}_2)} \label{dOpt}\end{equation}
where
\begin{align} \Var{\hat{\mu}_1} &=  \frac{\text{Var}(X_1)}{\pi^2} = \frac{1}{\pi^2}\left(\pi \sigma^2 + (1-\pi) \omega^2 + \pi(1-\pi)(\mu-\kappa)^2\right) \label{vmu1}\\
\Var{\hat{\mu}_2} &= \frac{\Var{X_2}}{(1-\pi)^2} = \frac{1}{(1-\pi)^2}\left((1-\pi)\sigma^2 + \pi \omega^2 + \pi(1-\pi)(\mu-\kappa)^2\right)\label{vmu2} \\
\text{Cov}(\hat{\mu}_1, \hat{\mu}_2) &= \frac{\text{Cov}(X_1,X_2)}{\pi(1-\pi)} = \frac{1}{\pi(1-\pi)}\left((1-\pi^2 - (1-\pi)^2)\mu\kappa - \pi(1-\pi)(\mu^2 + \kappa^2)\right) \label{cov}
\end{align} 
Derivations of these formulas are in the appendix.

Thus, the minimum variance unbiased estimator is 
\begin{equation} \hat{\mu}^* \equiv \hat{\mu}(d^*) = d^* \hat{\mu}_1 + (1-d^*) \hat{\mu}_2 \label{muOpt}
\end{equation}
where $d^*$ is defined as in (\ref{dOpt}).  Note that $d^*$ is strictly increasing in $\pi$, but at a rate that depends on $\sigma^2, \omega^2, \mu,$ and $\kappa$.  Intuitively, this means that the optimal estimator $\hat{\mu}^*$ puts more weight on the observation that is most likely to be correct. 

Figure \ref{dStar} plots the optimal $d^*$ for $\pi\in[0,0.5]$, since the solution is symmetric in $\pi$ when $L=2$. When $\pi=0.5$, $\Var{\hat{\mu}_1}=\Var{\hat{\mu}_2}$ so that $d^*=0.5$, regardless of the other parameter values.  When the variance of both the correct and incorrect distributions are the same (i.e., $\sigma^2 = \omega^2$), then $\Var{X_1}=\Var{X_2}$, and differences in $d^*$ reflect only changes in $\pi$.   When $\sigma^2 \neq \omega^2$, the optimal $d^*$ puts additional weight (relative to the equal variance case) on the estimator based on the $X_i$ that is more likely to come from the lower variance distribution.  The curve with $\sigma^2 = 1$ and $\omega^2 = 10$ is the extreme version of this scenario, and represents what may happen if $\kappa$ is estimated imprecisely.  The resulting $d^*$ assigns very low weight to the observation that is more likely drawn from the incorrect distribution.  

\begin{figure}[htbp]
\begin{center}
\caption{Optimal $d^*$ as a function of $\pi$ and $\sigma^2, \omega^2, \mu, \kappa$}
\includegraphics[width=0.8\textwidth]{./Figures/dStar.pdf}
\label{dStar}
\end{center}
\end{figure}

More generally, the estimator $\hat{\mu}^*$ can be computed for a sample of observations $(X_{i1}, X_{i2})_{i=1}^N$, where $X_{i1}$ is drawn from $F_X$ with probability $\pi_i$, and $X_{i2}$ is drawn from $F_X$ with probability $1-\pi_i$.  In this case, $d^*$ is calculated according to (\ref{dOpt}) using,
\begin{align*} \hat{\mu}_1 &= \frac{1}{N} \sum_{i=1}^N \frac{X_{i1}}{\pi_i} - \frac{1-\pi_i}{\pi_i}\kappa 
& \Var{\hat{\mu}_1} &=  \frac{1}{N^2}\sum_{i=1}^N \frac{g(\pi_i; \theta)}{\pi_i^2} \\
 \hat{\mu}_2 &= \frac{1}{N} \sum_{i=1}^N \frac{X_{i2}}{1-\pi_i} - \frac{\pi_i}{1-\pi_i}\kappa \ &\Var{\hat{\mu}_2} &= \frac{1}{N^2} \sum_{i=1}^N \frac{g(1-\pi_i; \theta)}{(1-\pi_i)^2} \end{align*}
$$\text{Cov}(\hat{\mu}_1, \hat{\mu}_2) = \frac{1}{N^2}\sum_{i=1}^N \frac{\text{Cov}(X_{1i}, X_{2i})}{\pi_i(1-\pi_i)} $$
where $g(p; \theta) = p \sigma^2 + (1-p) \omega^2 + p(1-p)(\mu-\kappa)^2$ is the variance of $X_{i\ell},$ for $\ell \in \{1,2\}$, that has probability $p$ of being drawn from the correct distribution.  


\subsection{Errors in $\hat{\pi}$}

The construction of $\hat{\mu}^*$ was based on the assumption that $\pi$ was known; this section studies the performance of $\hat{\mu}^*$ when only an estimate $\hat{\pi}$ is available. 

Suppose that we have an i.i.d. sample of observations $(X_{i1}, X_{i2})_{i=1}^N$, where $X_{i1}$ is drawn from $F_X$ with probability $\pi$, and $X_{i2}$ is drawn from $F_X$ with probability $1-\pi$.  In the context of record linkage, $X_{i1}$ and $X_{i2}$ may refer to two possible matches for an observation, and $\pi$ is the probability that $X_{i1}$ is the true match.  The estimated probabilities $\hat{\pi}$ may be obtained from a probabilistic record linkage procedure or reflect prior knowledge about the matching application\footnote{For example, $\hat{\pi}$ may reflect the econometrician's belief that ``Alicia" is more likely than ``Alex" to refer to the true match of an individual named ``Ali".}.

As observed in \citet*{ahl2019}, when $\pi$ is unknown, it is possible to construct an unbiased linear estimator of $\hat{\mu}$ by weighting all observations equally,
\begin{equation} \hat{\mu}^{AHL} =  \frac{1}{N}\sum_{i=1}^N X_{i1} + \frac{1}{N} \sum_{i=1}^N X_{i2} - \kappa \label{ahl}\end{equation}
The variance of this estimator is
\begin{equation}
\Var{\hat{\mu}^{AHL}} = \frac{\Var{X_{1i} + X_{2i}}}{N} 
\label{var_ahl}
\end{equation}
Note that $\Var{\hat{\mu}^{AHL}} = \Var{\hat{\mu}(\pi)} = \Var{\pi \hat{\mu}_1 + (1-\pi)\hat{\mu}_2}$, so that  $\Var{\hat{\mu}^{AHL}} \geq \Var{\hat{\mu}^*}$ if $\pi$ is known, with equality holding if and only if $\pi = 0.5$.  

Since $\hat{\mu}^{AHL}$ is unbiased regardless of the beliefs $\hat{\pi}$, it is interesting to study whether $\hat{\mu}^*$ continues to minimize the mean squared error when beliefs about $\pi$ are misspecified, i.e. $\hat{\pi} \neq \pi$.  Unless $\hat{\pi}=0.5$, the estimator $\hat{\mu}^*$ that uses $\hat{\mu}_1, \hat{\mu_2}$, and $d^*$ based on incorrect beliefs $\hat{\pi}$ will be biased.  For example, if $(\mu, \sigma^2, \kappa, \omega^2) = (0, 1, 1, 2)$ and $\pi=0.6$, but the econometrician believes $\hat{\pi}=0.9$, then
\begin{gather*}
\hat{\mu}_1 = \frac{1}{N} \sum_{i=1}^N \frac{X_{i1}}{\hat{\pi}} - \frac{1-\hat{\pi}}{\hat{\pi}} = \frac{1}{N} \sum_{i=1}^N \frac{10}{9} X_1 - \frac{1}{9} \\
\hat{\mu}_2 = \frac{1}{N}\sum_{i=1}^N \frac{X_2}{1-\hat{\pi}} - \frac{\hat{\pi}}{1-\hat{\pi}} =  \frac{1}{N} \sum_{i=1}^N10 X_2 - 9
\end{gather*}
both of which are biased, because $E[\hat{\mu}_1] = \frac{1}{3}$ and $E[\hat{\mu}_2] = -3$.  Similarly, using $\hat{\pi}$ instead of $\pi$ in (\ref{vmu1})-(\ref{cov}) to calculate $\Var{\hat{\mu}_1},\ \Var{\hat{\mu}_2}$, and Cov$(\hat{\mu}_1, \hat{\mu}_2)$ results in choosing $d^* = 0.987$, and Bias(${\hat{\mu}}^*) = 0.292$ and $\Var{\hat{\mu}^*} = \frac{1.94}{N}$.

By comparison, Bias($\hat{\mu}^{AHL}) =  0$ and $\Var{\hat{\mu}^{AHL}} = \frac{3}{N}$, so we can solve for $N$ such that $MSE_n(\hat{\mu}^{AHL}) < MSE_n(\hat{\mu}^*)$ for all $n \geq N$:
$$0.292^2 + \frac{1.94}{N} = \frac{3}{N} \implies N = 12.43$$ 
This example suggests that for fixed $\theta = (\mu, \sigma^2, \kappa, \omega^2)$ and $N$, we can compare the ratio of $MSE_n(\hat{\mu}^*; \theta)/MSE_n(\hat{\mu}^{AHL};\theta) $ for different values of Bias($\hat{\pi}$).  Alternatively, for a fixed value of Bias($\hat{\pi}$), we can calculate the minimum sample size $N$ such that it is more efficient to use $\hat{\mu}^{AHL}$. 

Figures 2 and 3 plot the bias and variance of $\hat{\mu}^*$ as a function of the mis-specified beliefs $\hat{\pi}$ for different values of $\theta$.  The bias is quadratic in $|\hat{\pi}-\pi|$, with zero bias at $\hat{\pi}=\pi$ and $\hat{\pi}=0.5$.  The variance of $\hat{\mu}^*$ is not minimized at $\hat{\pi}=\pi$, but at some value determined by $\sigma^2, \omega^2$, $(\mu-\kappa)^2$, and Bias$(\hat{\pi})$.  The variance term is less interesting than the bias, because $\Var{\hat{\mu}^*}\to0$ as $N\to\infty$, whereas the bias does not disappear.  

This issue is reflected in Tables 1-3, which display the ratio of the $MSE_N(\hat{\mu}^{AHL};\theta)/MSE_N(\hat{\mu}^*;\theta)$ for $N=10, 100$, and $1000$, when $\hat{\mu^*}$ is calculated for different values of $\hat{\pi}$.  Although the values in these tables are calculated for $\theta = (\mu, \sigma^2, \kappa, \omega^2) = (0,1,1,2)$ the same pattern of results appears for other parameter combinations included in the Appendix. 

Although it is rarely the case that $N=10$ in practice, Table 1 illustrates how, even in small samples, the AHL estimator can be more efficient than $\hat{\mu}^*$ for incorrect beliefs such that $|\hat{\pi}-\pi| >  0.35$.   For $N=100$, this tolerance for error in $\hat{\pi}$ decreases to $|\hat{\pi}-\pi| >  0.15$; and, for $N=1,000$, $\hat{\mu}^*$ outperforms $\hat{\mu}^{AHL}$ only if $\hat{\pi}=\pi$.  This pattern may suggests that incorporating knowledge about $\pi$ offers potential efficiency gains for estimators applied to small samples, but that the potential gains, as well as the tolerance for errors in $\hat{\pi}$, decrease with sample size.  Whether this result holds more generally requires additional work to incorporate heterogenous $\pi_i$ and $L>2$ observations of $X_{\ell}$.  

\begin{figure}[htbp]
\begin{center}
\caption{Bias of $\hat{\mu}^*$ as a function of $\hat{\pi}$ }
\vspace{5pt}
\includegraphics[width=\textwidth]{./Figures/bias_plot.pdf}
\label{bias_plot}
\end{center}
\end{figure}

\begin{figure}[htbp]
\begin{center}
\caption{Variance of $\hat{\mu}^*$ as a function of $\hat{\pi}$ with $N=1$}
\vspace{5pt}
\includegraphics[width=\textwidth]{./Figures/var_plot.pdf}
\label{var_plot}
\end{center}
\end{figure}

\input{./Figures/compare_10.tex}
\input{./Figures/compare_100.tex}
\input{./Figures/compare_1000.tex}

\subsection{Incorporating $\pi$ in linear regression}

Suppose we have two matches $\{y_{i1}, y_{i2}\}_{i=1}^N$ for each observation.  We get the same conditions for unbiasedness of the OLS estimator if we consider using a linear combination of the $y$'s, as in the model:
\begin{equation} a_1 y_{i1} + a_2 y_{i2} - \kappa = x_i'\beta + \varepsilon_i, \ \hspace{10pt} \Var{\varepsilon | x_i } = \sigma^2  \end{equation}
Then the OLS estimator is
$$ \hat{\beta} = \left(\frac{1}{N}\sum_{i=1}^N x_i x_i'\right)^{-1} \left(\frac{1}{N}\sum_{i=1}^N x_i'(a_1 y_{i1} + a_2 y_{i2} - \kappa)\right) $$
and
\begin{align*}
E\left[\hat{\beta} - \beta \Big| x_i \right] &= E[x_ix_i']^{-1} E[x_i'(a_1 y_{i1} + a_2 y_{i2} - \kappa] \\
&= \beta(a_1 \pi + a_2 (1-\pi)) + E[x_ix_i']^{-1}E[x_i](a_2 \pi + (1-\pi)a_1 - a_3) \kappa 
\end{align*}
Unbiasedness requires the same conditions on $a_1, a_2,$ and $a_3$ as derived in Lemma 1, i.e.
\begin{align*}
a_2(a_1) &=  \frac{1-\pi a_1}{1-\pi} \\ a_3(a_1) &= \frac{\pi}{1-\pi} + \frac{a_1 - 2\pi a_1}{1-\pi} 
\end{align*}
which means that any unbiased linear estimator $\hat{\beta}$ can be written as a linear combination of unbiased estimators that use only $y_{i1}$ or $y_{i2}$,
\begin{align*}
\hat{\beta}_{1} &= \left(\frac{1}{N}\sum_{i=1}^N x_i x_i'\right)^{-1}\frac{1}{N}\sum_{i=1}^N \frac{x_i y_{i1}}{\pi} - \frac{1-\pi}{\pi}\kappa \\
 \hat{\beta}_{2} &= \left(\frac{1}{N}\sum_{i=1}^N x_i x_i'\right)^{-1}\frac{1}{N}\sum_{i=1}^N \frac{x_i y_{i2}}{1-\pi} - \frac{\pi}{1-\pi}\kappa 
 \end{align*}
 and so the minimum variance estimator is $\hat{\beta}^* = d^* \hat{\beta}_1 + (1-d^*)\hat{\beta}_2$, where 
 \begin{equation}
 d^* = \frac{\Var{\hat{\beta}_{2} \Big| x_i} - \text{Cov}\left(\hat{\beta}_1, \hat{\beta}_2 \Big| x_i \right)}{\Var{\hat{\beta}_1\Big| x_i} + \Var{\hat{\beta}_{2}\Big| x_i} - 2 \text{Cov}\left(\hat{\beta}_1, \hat{\beta}_2 \Big| x_i \right)}
 \end{equation}
and we can repeat the exercise in the previous sections, comparing variance and bias for misspecified beliefs $\hat{\pi}$ and different parameter combinations.  The choice of the weights $d^*$ that give the optimal $\hat{\beta}^*$ is now complicated by the fact that it depends on the second moments of $X_i$, however the formulas for $\Var{\hat{\beta}_i \Big| x_i }$ are the same as in (\ref{vmu1})-(\ref{cov}), but replacing $\mu, \sigma^2, \kappa,$ and $\omega^2$ with (under conditional homoskedasticity),
\begin{align*}
\tilde{\mu} &= \beta \\
\tilde{\sigma}^2 &=  \sigma^2 E[x_ix_i]^{-1}\\
\tilde{\kappa} &= E[x_ix_i']^{-1}E[x_i]\kappa \\
\tilde{\omega}^2 &= (\omega^2 + \kappa^2)E[x_ix_i']^{-1}
\end{align*}
and the bias and variance should behave as in Figures \ref{bias_plot} and \ref{var_plot} for misspecified beliefs $\hat{\pi} \neq \pi$.

\section{Monte Carlo Study}

In order to compare how these methods perform in practice, I conduct a Monte Carlo study where each replication consists of (i) generating an $x$- and $y$-datafile, (ii) linking the $x$- and $y$-datafiles to obtain matched data of the form (\ref{data}), and (iii) estimating (\ref{model}) using the matched datasets and the techniques described in Sections 3 and 4.  Since the performance of the estimators depends on whether multiple matches or estimated probabilities are available, Step (ii) involves applying four record linkage procedures, each of which outputs a distinct dataset.  The remainder of this section describes in detail how I generate data for a single replication of the Monte Carlo study, with a special focus on the record linkage procedures implemented in Step (ii).  

\subsection{Generating the $x$- and $y$-datafiles}

I begin by constructing a ``ground truth" dataset with 1000 observations of $(x_{1i}, x_{2i}, y_i, w_i)$, where $x_{1i}$ and $x_{2i}$ are mutually independent, i.i.d draws from Bernoulli(0.5) and Normal(0,2) distributions, respectively.s  The $y_i$ values are generated according to \begin{gather}
y_i = \beta_0 + \beta_1 x_{1i} + \beta_2 x_{2i} + \varepsilon_i, \hspace{10pt} 
\varepsilon_i\  |\  x_{1i}, x_{2i} \overset{i.i.d}{\sim} \mathcal{N}(0, \sigma^2) 
\end{gather}
where $\varepsilon_i$ are independent draws from a Normal(0,2) distribution.  I chooses $(\beta_0, \beta_1, \beta_2, \sigma^2) = (2, 0.5, 1, 2)$, so that estimating the correctly specified linear regression model yields an $R^2$ value of approximately 0.50.  

The vector of identifying variables, $w_i$, includes a first name, last name, and birth year.  In total, there are 960 unique first and last name combinations, so multiple observations will be assigned the same first and last name.  The birth years are drawn at random from a uniform distribution over the set of integers between 1900 and 1925.  The resulting dataset resembles the top panel of Figure \ref{sample_dta}.  
 
 \input{./Figures/synthetic.tex}
 
Next, I split the ground truth dataset into the $x$- and $y$-datafiles, as in the bottom panel of Figure \ref{sample_dta}.  The $x$-datafile contains values of $(x_{i1},x_{i2})$ for 500 observations selected at random from the ground truth dataset.  The identifiers in the $x$-datafile are equal to the original $w_i$ plus some random transcription error.  The probability of introducing a certain type ofs typographical error is equal to that reported for the 1940 Census data in \cite{abe2019}\footnote{For example, 7\% of observations have misreported first names and 17\% of observations have misreported last names.} These errors include deleting characters (e.g., ``Anderson"  becomes ``Andersn"), exchanging vowels (e.g., ``Rachel" becomes ``Rachal"), and swapping English phonetic equivalents (e.g. ``Ellie" becomes ``Elie").  For half of the observations, I introduce random errors in the birth year drawn from a Normal(0, 2.5) distribution and rounded to the nearest integer.  

The $y$-datafile includes all 1,000 values of $y_i$ from the ground truth data, along with the original identifiers $w_i$.  The aim of this construction is to make it likely that some observations in the $x$-datafile will be linked to multiple values of $y$.  The next section describes the record linkage methods used to link the $x$- and $y$-datafiles. 

\subsection{Linking the $x$- and $y$-datafiles}
Taking the $x$- and $y$-datafiles as given, I implement four record linkage procedures to obtain matched datasets with the general structure in (\ref{data}).  This section offers a brief overview of these methods, however the interested reader should refer to \citet*{harron_book, christen2012} and \citet*{herzog07} to learn more about modern record linkage methods. 

For the purposes of this paper, I define a record linkage procedure as a set of decisions about (i) selecting and standardizing the identifying variables in $w_i$ and $w_j$, (ii) choosing which $(i,j)$ pairs to consider as potential matches, (iii) defining how to measure (partial) agreement between $(w_i,w_j)$, and (iv) designating $(i,j)$ pairs as matches.  

Step (i) accounts for differences in $w_i$ and $w_j$ that arise as a result of transcription error or misreporting, even when observations $i$ and $j$ refer to the same individual.   In practice, the researcher may define binary matching variables that correspond with events such as $i$ and $j$ were born in the same month or $i$ and $j$ have last names ending with the same three characters.  If the matching variables include full strings, then the researcher may standardize them by removing spaces and non-alphabetic characters, replacing common nicknames with full names, or pre-processing names with phonetic algorithms to account for possible misspellings.

\addlinespace
\textbf{Example 2.}  The identifiers in the simulated data do not include non-alphabetic characters, but do include misspelled names, so I pre-process all of the first and last names using the New York State Identification and Intelligence (NYSIIS) phonetic algorithm, and include these phonetically-spelled names among the matching variables.  The other matching variable is birth year, which does not require standardization.   Other popular phonetic algorithms include Soundex \citep*{soundex} and Metafone \citep*{philips90}; however, I assume that the NYSIIS algorithm performs sufficiently well for the purposes of my analysis, given that the names I use are selected from among the most common names assigned at birth in the present-day United States.  
\addlinespace

Step (ii) reduces the computational burden of a matching procedure when $N_x \times N_y$ is large, by dividing observations into non-overlapping ``blocks" based on their values of $w_i$ or $w_j$.  Only pairs assigned to the same block are considered as potential matches, and pairs that belong to different blocks are automatically designated as non-matches.  Thus, blocking variables should be recorded with minimal error, otherwise blocking can increase the Type II error rate. 

\addlinespace
\textbf{Example 2 (cont'd).} Given the size of my simulated datafiles, I do not need to impose any blocking rule for computational feasibility; however, the age-band threshold imposed by my deterministic matching methods acts as one.  These methods require that potential matches have recorded birth years that lie within a 2-year band.  Since I generate errors in the recorded birth year by rounding independent, random draws from a Normal(0, 2.5) distribution to the nearest integer, about 12 percent of these errors should result in true matches outside the threshold.  Furthermore, only half of the observations in the $x$-datafile contain errors in their recorded birth year, so this blocking structure should imply a Type II error rate of about 6 percent.  Out of the 500 observations in the $x$-datafile, this corresponds to approximately 28 false non-matches. 
\addlinespace

Step (iii) defines a metric for quantifying the similarity between non-numeric variables, such as the Jaro-Winkler distance or Levenshtein ``edit" distance for strings.  This allows the researcher to declare as a ``name match", or ``partial name match" any observation pair whose string distance is lower than a pre-specified threshold.  These metrics are related to, but different from the standardization methods described in Step (ii).  This is pointed out by \citet*{arp2018}, who observe that ``Abramtziky" is coded differently than ``Abramitzky" using the NYSIIS algorithm, but the Jaro-Winkler distance between these two names is very low (0.02, where the minimum distance is 0, and the maximum distance is 1).  Also, ``James Tennes" and ``James Thomas" have the same NYSIIS code, but the Jaro-Winkler distance between ``Tennes" and ``Thomas" is 0.4 

\addlinespace
\textbf{Example 2 (cont'd).}  The probabilistic record linkage methods in this paper use Jaro-Winkler distances to calculate the similarity between strings.  This metric gives higher weight to discrepancies in the first part of the string, as this is where errors are less likely to be made when recording names \citep*{jaro, winkler06}.  The Jaro-Winkler distance is also the default string metric for many record linkage packages, so this choice best reflects how researchers often match datasets in practice. 
\addlinespace

Whereas Steps (i)-(iii) involve decisions about pre-processing data that can be incorporated in any linkage procedure, Step (iv) is where the most meaningful differences among procedures arise.  The decision to match an $(i,j)$ pair requires trading off the possibility of introducing Type I or Type II error.  Probabilistic methods developed by \cite{fellegi69} show how to construct the optimal linkage rule subject to pre-specified tolerances for Type I and Type II errors.  Deterministic methods offer a proxy for these methods.   The rest of this section is devoted to discussing each method in detail.

\subsubsection{Deterministic Methods}
The deterministic matching methods used in this paper are based upon those used by \citet*{abe2012, abe2014, abe2019b}, and \cite{ferrie96}.  I implement two versions of the same method.  The first matches each observation in the $x$-datafile to at most one observation in the $y$-datafile, and discards any observations that result in multiple matches.  The second version designates as a match \textit{any} pair of observations that have the same phonetically spelled first and last names, and whose birth years fall within a 2-year band, which can result in linking a single observation to multiple matches. 

The basic algorithm that I use is as follows, 
\begin{enumerate}
\item Use the NYSIIS phonetic algorithm to obtain phonetically-spelled versions of the names in the $x$- and $y$-datafiles.
\item Restrict the sample to people in the $x$-datafile with unique first name, last name, birth year, and $x_{i}$ combinations. 
\item For each record $i$ in the $x$-datafile, search for a record $j$ in the $y$-datafile whose phonetically spelled first and last names and birth year match exactly.  
\begin{enumerate}
\item If there is a \textit{unique} match, designate $(i,j)$ as a match, and stop searching for additional possible matches. 
\item If there are multiple possible matches in the $y$-datafile, discard the observation $i$.
\item If there are no observations in the $y$-datafile that match $i$'s exact year of birth, search for a match within $\pm$1 year of $i$'s reported birth year; and, if this is unsuccessful, search for a match within $\pm$2 years.  If $i$ matches to multiple observations at any point, or if none of these attempts produces an exact name match, then discard the observation.
\end{enumerate}
\item Repeat Steps 2 and 3 for each record in the $y$-datafile, searching for matches in the $x$-datafile.  
\item Return the matched dataset equal to the intersection of the two sets of matches produced by Steps 3 and 4. 
\end{enumerate}
I implement the version that allows for multiple matches in exactly the same way, except that I replace Step 3 with,
\begin{enumerate}
\item[3.$^*$] Designate as a match any observation in the $y$-datafile that matches $i$'s phonetically spelled first and last name exactly, and whose birth year falls within $\pm$2 years of $i$'s birth year. 
\end{enumerate}

Although there are many ways to alter the above procedure, such as using a $\pm5$-year age band, replacing NYSIIS with another phonetic algorithm, or allowing for partial string agreement by incorporating Jaro-Winkler string distances, I design my methods to mimic the algorithm from \citet*{abe2019}.   As discussed above, I predict that the choice of the 2-year age band, combined with my data generation process, will result in a Type II error rate of about 5.7 percent for the deterministic methods.  However, the focus of this paper is to study estimation methods for linked data, so I favor simplicity over choosing the optimal variant, and defer to \citet*{bailey2017} and \citet*{abe2019} for a discussion of these matters.  

\subsection{Probabilistic Method}

The probabilistic matching methods implemented in this paper are implemented using the fastLink package in \texttt{R} created by \citet*{enamorado2019}.  Their methods are based upon the canonical work of \cite{fellegi69}, which I now review. 

\cite{fellegi69} present the record linkage task as a classification problem, where each $(i,j)$ record pair belongs either to the set of matches $(M)$, or non-matches $(U)$.  If the pairs are evaluated according to $K$,  comparison criteria, represented as a \textit{comparison vector}, $$\mathbf{\gamma_{ij}}= (\gamma_{ij}^1, \dots, \gamma_{ij}^{k}, \dots, \gamma_{ij}^K)$$ then the probability of observing a particular configuration of $\gamij$ can be represented by the mixture distribution:
\begin{equation}
P(\gamij) = P(\gamij | M) p_M + P(\gamij | U) p_U 
\label{mm}
\end{equation}
where $P(\gamij | M)$ and $P(\gamij | U)$ are the probabilities of observing the pattern $\gamij$ conditional on the record pair $(i,j)$ belonging to $M$ or $U$, and $p_M$ and $p_U = 1-p_M$ are the marginal probabilities of observing a matched or unmatched pair. 

Using Bayes' Rule, we can write the probability of $(i,j)$ belonging to $M$ or $U$, conditional on observing $\gamij$, as
\begin{align} P(M | \gamij) &= \frac{p_M P(\gamij | M)}{P(\gamij)} \\ 
P(U | \gamij) &= \frac{p_U P(\gamij | U)}{P(\gamij)}
 \end{align}
If we can estimate the parameters of the mixture distribution in (\ref{mm}), then we can estimate the probability that any two records refer to the same entity using the formulas above.  These probabilities can in turn be used to designate pairs as matches, or to quantify uncertainty about the matched dataset.  

In the context of this paper, the comparison vector $\gamij$ reflects agreements between $w_i$ and $w_j$, such as ``$i$ and $j$ have the same birth year" or ``$i$ and $j$ have the same phonetically spelled last name."  Yet even if all of the $\gamma_{ij}^{k}$ are binary, $\gamij$ has $2^K -1$ possible configurations of $\gamij$, and so it is convenient to assume the comparison fields $\gamma_{ij}^{k}$ are independent across $k$ conditional on match status.  This reduces the number of parameters necessary to describe each mixture class, since we can factor 
 \begin{equation} 
 P(\gamma_{ij} | C) = \prod_{k=1}^K P(\gamma_{ij}^{k} | C)^{\gamma_{ij}^{k}}(1-Pr(\gamma_{ij}^{k} | C))^{1-\gamma_{ij}^{k}} \hspace{20pt} C\in \{M, U\} 
 \label{eq:condInd}
 \end{equation}
In principle, this assumption can be relaxed using log-linear models, as in \cite{larsen_rubin_2001}; however, the conditional independence assumption is appropriate for my application, because I generate the errors for different categories of $w_i$ independently. 
 
Since membership to $M$ or $U$ is not observed, \cite{larsen_rubin_2001} suggest using the expectation-maximization (EM) algorithm from \citet*{em} to simultaneously estimate the parameters in (\ref{mm}) and classify record pairs as matches or non-matches.  Crucially, there is no restriction that the posterior match probabilities in (30) sum to 1 for a fixed observation $i$.  Obtaining unique matches requires using a linear sum assignment program that maximizes the sum of the posterior matching probabilities subject to the constraint that no observations in either datafile can be matched multiple times. 

The fastLink package by \citet*{enamorado2019} estimates the posterior match probability for each pair of observations in the sample, as outputted by the EM algorithm.  Their method allows the user to specify a lower bound for the posterior probability of a match that will be accepted; I set this equal to 0.7 because the default value of 0.85 does not result in any matches.   The fastLink algorithm also allows the user to specify whether unique matches are desired, and, if so, returns the set of matches that solves the linear sum assignment program assigned above.  I use this option to obtain two versions of linked data, one that enforces unique matches, and one that accepts all matches with posterior match probabilities greater than 0.7, which I then normalize to obtain estimates of $\pi_{i\ell}$. 

\section{Monte Carlo Results}

Following the data generating process described in Section 5.1, I generate 1,000 $x$- and $y$-dataset pairs, such that each of the 500 observations in the $x$-datafile has a unique, true match in the $y$-dataset, but the identifiers in the $y$-dataset may repeat, and the identifiers in the $x$-dataset contain random errors.  I then match each dataset pair a total of four times, using two deterministic matching methods and two probabilistic record linkage methods that produce either single or multiple matches per observation, as summarized in Table \ref{overview}.


\input{./Figures/overview_tab.tex}

Each linkage method produces a distinct matched dataset, and so the matching step produces a total of 4,000 matched datasets.  For each dataset, I compute and compare the following estimators:
\begin{enumerate}
\item the OLS estimator that treats each link as a distinct observation 
\item the OLS estimator that uses only observations assigned a unique match
\item the SW estimator 
\item the AHL estimator 
\item the OLS estimator that uses all 500 correctly linked record pairs
\end{enumerate}

\subsection{Matching results}
The first column of Table \ref{match_rate} reports the proportion of observations in the $x$-datafile that are linked to at least one observation in the $y$-datafile, averaged across the Monte Carlo replications.  These rates range between 71 and 79 percent across methods, however Figure \ref{match_hist} shows that the deterministic method with multiple matches consistently matches more distinct observations than any other procedure.  Additionally, the probabilistic methods have the same match rate on average, which suggests that allowing for multiple matches adds additional matches per observations, as opposed to matching new individuals.  This is likely an artifact of the fastLink algorithm, because the posterior probability threshold for designating a match is the same for both methods.  By contrast, the match rate increases for the deterministic algorithm when multiple matches are allowed, because it matches observations that were discarded otherwise. 

The second column of Table \ref{match_rate} displays the average number of links assigned by each matching procedure.  For the methods that produce multiple matches, each $(i, j)$ combination counts as a distinct link, so that an observation with $L$ linked outcomes counts as $L$ matches.  To explore whether these numbers are driven primarily by linking the observations to many matches, or by linking more observations to possibly multiple, but fewer, matches, I report the average number of links per observation in Table \ref{multi_L}.  On average, the deterministic method seems to assign larger $L_i$ per observation.  Whereas the probabilistic method assigns a unique match to 59 percent of observations, and two matches to 33 percent of observations, the deterministic method assigns, on average, one, two, and three matches to 52, 35, and 11 percent of observations, respectively.  Both algorithms tend not to assign more than four matches for many observations.  Note that these probabilities do not sum to one, because they reflect the average of $P(L_i = \ell)$ across 1,000 observations, and not the average \textit{distribution} of $L_i$ across datasets. 

Of the methods that match pairs uniquely, the deterministic matching algorithm seems to produce higher quality matches, as measured by its low Type I error (0.03) relative to that of the probabilistic method (0.11).  It also produces a lower Type II error -- the deterministic method fails to match 31 percent of true links, and the probabilistic method misses 35 percent.  As discussed in Section 5, about 6 percent of the Type II error can be attributed to the blocking structure imposed by the deterministic algorithm, yet it still outperforms the probabilistic method.

The last column in Table \ref{match_rate} reports the average probability that the set of matches $\{y_{i\ell}\}_{\ell=1}^{L_i}$ contains the true match.  This is an important metric to study, because the estimation methods used in this paper assume that this probability is equal to 1.  Notably, this assumption is most likely to fail for the probabilistic method with unique matches (it finds the correct match only 89 percent of the time), but allowing for multiple matches in improves this probability significantly.   Both of the deterministic methods perform very well on this metric, as they include the correct match 97 and 99 percent of the time.  Breaking down this probability by the number of matches $L_i$ in Table \ref{multi_L} shows that allowing for multiple matches increases the probability that the true match is included in the sample.  

% Match Rate Table 

\begin{table}[htbp]
\let\center\empty
\let\endcenter\relax
\centering
\caption{Summary of matching algorithm performance}
\vspace{10pt}
\resizebox{\textwidth}{!}{\input{./Figures/match_rates.tex}}
\label{match_rate}
\end{table}

\begin{table}[htbp]
\let\center\empty
\let\endcenter\relax
\centering
\caption{Performance of multiple match methods by value of $L_i$}
\vspace{10pt}
\resizebox{\textwidth}{!}{\input{./Figures/multi_tab.tex}}
\label{multi_L}
\end{table}

%  Match Rate Histograms 
\begin{figure}[h!]
\begin{center}
\caption{Match Rates by Linking Procedure } 
\includegraphics[width=0.9\textwidth]{./Figures/match_rate.pdf}
\label{match_hist}
\end{center}
\end{figure}

\subsection{Estimation Results}

Based on Figure 5, the AHL estimator appears to perform better than the SW estimator for both datasets, because the SW estimator for $\beta_0$ is not centered around the true value, and the distribution of the SW estimator has fatter tails than that of the AHL estimator for all parameter values.  The AHL estimator also performs better than the SW estimator as measured by the median absolute deviation across the 1,000 replications, and for both datasets (see Table\ref{mad}).   Furthermore, the AHL estimator performs better than the OLS estimator that uses only those observations assigned $L_i =1$ by the methods that allow $L_i$ to vary freely, whereas the SW estimator performs worse.  The AHL and SW estimators cannot be compared using the datasets matched by ABE Single or PRL Single, because they are both equal to the Naive OLS estimator when $L_i = 1$.  

I calculate the AHL estimator by setting $\hat{g}(w_i, L_i)$ equal to the unconditional mean of the $y_j$, which, despite being the correct choice for my data generating process, means that the AHL estimator may perform better in scenarios where $w$ or $L$ is correlated with $y$.  By contrast, the SW estimator is biased when the matching variables $w$ are correlated with $y$, so the gains in accuracy achieved by the AHL estimator relative to the SW estimator reported here can be interpreted as a lower bound.  

Table \ref{mad} also compares the AHL and SW estimators to the OLS estimator that uses only the true matches appearing in the matched datasets.  As expected, no estimator performs as this theoretical estimator, however neither AHL nor SW performs significantly worse in terms of median absolute deviations. 

Figure \ref{benchmark} serves as both a benchmark for comparing the AHL and SW methods, as well as an additional metric for evaluating the performance of the matching methods.   Note that the OLS estimator that incorporates all matches (counting multiple links as distinct observations) suffers from attenuation bias in its estimate of $\hat{\beta}_2$.  This is because the additional matches, by necessity, introduce measurement error.  

\begin{table}[h!]
\let\center\empty
\let\endcenter\relax
\centering
\caption{Median Absolute Deviations for Estimators}
\vspace{10pt}
\resizebox{0.9\textwidth}{!}{\input{./Figures/est_tab.tex}}
\label{mad}
\end{table}

% distribution of estimators
\begin{figure}[htbp]
\label{ahl_sw_fig}
\caption{Monte Carlo Distribution of the SW and AHL Estimators}
\begin{center}
\includegraphics[width=\textwidth]{./Figures/ahl_sw.pdf}
\end{center}
\end{figure}

\begin{figure}[htbp]
\begin{center}
\label{benchmark}
\caption{Monte Carlo Distribution of Benchmark OLS Estimators}
\includegraphics[width=1.1\textwidth]{./Figures/compare.pdf}
\end{center}
\end{figure}

\section{Conclusion}

The Monte Carlo study in this paper involved arbitrary choices about the types of identifiers and the errors added to them that may influence the results in important ways, and so further work is necessary to determine whether the patterns described in Sections 4 and 6 generalize to other settings.  For now, both the theoretical and numerical analysis in this paper suggest that allowing for multiple matches may offer a solution for analyzing data that are linked with imperfect and non-unique identifiers.  Furthermore, my theoretical results suggest that multiple matches should be weighted equally for asymptotically linear estimators such as OLS and GMM, unless the match probability can be estimated exactly or the sample size is very small.  

\newpage

\singlespacing
\bibliography{./Deadlines/proposal_bib} 
\bibliographystyle{econometrica}

\newpage
\doublespacing

\section{Appendix}

\subsection{Proofs}
\noindent \textit{\textbf{Lemma 1.}} Any linear unbiased estimator of $\mu$ of the form
\begin{equation}
\hat{\mu} = a_1X_{1} + a_2 X_2 -  a_3 \kappa \label{mu} \end{equation}
with $a_1$ and $a_2 >0$, can be written as a linear combination of 
\begin{align*}
\hat{\mu}_1 &= \frac{X_1}{\pi} - \frac{1-\pi}{\pi} \kappa \\
\hat{\mu}_2 &= \frac{X_2}{1-\pi} - \frac{\pi}{1-\pi}\kappa 
\end{align*}
\textbf{Proof.} The expectation of $\hat{\mu}$ is 
$$ E[\hat{\mu}] = (a_1 \pi + a_2 (1-\pi))\mu + (a_1(1-\pi)+a_2\pi - a_3)\kappa $$
so that unbiasedness requires choosing $a_1, a_2$ and $a_3$ that satsify,
\begin{gather}
    a_1\pi + a_2(1-\pi) = 1 \implies a_2(a_1) = \frac{1}{1-\pi} - \frac{a_1 \pi}{1-\pi} \\
    a_1 (1-\pi) + a_2 \pi = a_3 \implies a_3(a_1) = \frac{\pi}{1-\pi}  + \frac{a_1 - 2a_1 \pi}{1-\pi} 
\end{gather}
Rewriting $\hat{\mu}$ as a function of $a_1$,  
 $$\hat{\mu}(a_1) = a_1 X_1 +  \left(\frac{1}{1-\pi} - \frac{a_1 \pi}{1-\pi}\right)  X_2 - \left(\frac{\pi}{1-\pi} + \frac{a_1 - 2a_1\pi}{1-\pi}\right)\kappa $$ 
which, after some rearranging, can be written as
$$\hat{\mu}(a_1) = (a_1 \pi) \hat{\mu}_1 + (1-a_1\pi) \hat{\mu}_2 $$
which completes the proof.  

\noindent \textit{\textbf{Lemma 2.}} Suppose the data consist of $\{X_{\ell}\}_{\ell=1}^{L}$, where each $X_{\ell}$ is drawn from the correct distribution with probability $\pi_{\ell}$ and from the incorrect distribution with probability $1-\pi_{\ell}$, and exactly one $X_{\ell}$ is drawn from the correct distribution.  Then, any unbiased estimator of $\mu$ that places positive weight on all of the $\{X_{\ell}\}$ can be written as a linear combination of $\hat{\mu}_{\ell}$, the unbiased estimator of $\mu$ that only uses $X_{\ell}$, 
$$ \hat{\mu}_{\ell} = \frac{X_{\ell}}{\pi_{\ell}}  - \frac{1-\pi_{\ell}}{\pi_{\ell}} \kappa, \hspace{10pt} \ell = 1, \dots, L $$
\textbf{Proof.}  The proof follows by induction.  Lemma 1 proves the base case for $L=2$.  Assume that $\hat{\mu}^{(L-1)} = \sum_{\ell=1}^{L-1} b_{\ell} \hat{\mu}_{\ell}$.  Construct $\hat{\mu}^{(L)} = a_1 \hat{\mu}^{(L-1)} + a_2 X_L - a_0 \kappa$, so that
$$ E[\hat{\mu}^{(L)}] = (a_1 + a_2 \pi_L) \mu + (a_2(1-\pi_L) - a_0) \kappa $$
Unbiasedness requires that
\begin{align*}
a_2(a_1) &=  \frac{1-a_1}{\pi_L} \\ 
a_3(a_1) &= \left(\frac{1-\pi_L}{\pi_L}\right)\left(\frac{1-a_1}{\pi_L}\right)
\end{align*}
Plugging this into $\hat{\mu}^{(L)}$ yields,
\begin{align*} \hat{\mu}^{(L)} &= a_1 \hat{\mu}^{(L-1)} + (1-a_1)\underbrace{\left(\frac{X_L}{\pi_L} - \frac{1-\pi_L}{\pi_L}\right)}_{\hat{\mu}_L} \\
\implies \hat{\mu}^{(L)} &= \sum_{\ell=1}^{L-1} a_1 {b_\ell} \hat{\mu}_{\ell} + (1 - a_1) \hat{\mu}_{\ell}
\end{align*}
which completes the proof.  

\subsection{Variance formulas}
$\Var{X_1}$ and $\Var{X_2}$ are calculated using the law of total variance, using the random variable $D = 1$ if $X_1$ is drawn from the correct distribution (and $X_2$ is drawn from the incorrect distribution), and $D=0$ otherwise:
\begin{align*} \Var{X_1} &= E[\Var{X_1 | D}] + \Var{E[X_1| D]} \\ 
&= P(D=1)\sigma^2 +  P(D=0)\omega^2 + \Var{\mu D + \kappa (1-D)} \\
&= \pi \sigma^2 + (1-\pi) \omega^2 + \pi(1-\pi)(\mu-\kappa)^2
\end{align*}
The same trick can be applied to calculate $\Var{X_2}$

\subsection{Additional MSE Tables}

\input{./Figures/compare_1.tex}
\input{./Figures/compare_2.tex}
\input{./Figures/compare_3.tex}
\input{./Figures/compare_4.tex}
\input{./Figures/compare_5.tex}

\end{document}