\documentclass[12pt]{article}
\usepackage[margin=0.1in]{geometry}
%\usepackage[nomarkers,nofiglist,notablist]{endfloat}
\usepackage{xcolor}
\usepackage{framed}
\usepackage{enumitem}
\usepackage{adjustbox}
\usepackage{natbib}
\usepackage{chngpage}
\usepackage{mathtools,xparse}
\usepackage{graphics}
\usepackage{tikz}
\usepackage{tabu}
\usepackage{tikz-cd}
\colorlet{shadecolor}{orange!15}
% \definecolor{shadecolor}{rgb}{255,128,0}\
\usepackage{float}
\usepackage{fullpage} % Package to use full page
\usepackage{parskip} % Package to tweak paragraph skipping
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{hyperref}
\usepackage{pdflscape}
\usepackage{setspace}
\usepackage{graphicx} % Allows including images
\usepackage{booktabs} % Allows the use of \toprule, \midrule and \bottomrule in tables
\usepackage{longtable}
\usepackage{indentfirst}
\usetikzlibrary{arrows,shapes,positioning,shadows,trees}
\usepackage{array}
\usepackage{wrapfig}
\usepackage{multirow}
\usepackage{pdflscape}
\usepackage{threeparttable}
\usepackage{makecell}
\usepackage[normalem]{ulem}
\newcommand{\PreserveBackslash}[1]{\let\temp=\\#1\let\\=\temp}
\newcolumntype{L}[1]{>{\PreserveBackslash\raggedright}m{#1}}
\newcolumntype{R}[1]{>{\PreserveBackslash}p{#1}}
\newcolumntype{C}[1]{>{\PreserveBackslash\centering}m{#1}}
\newcommand{\Var}[1]{\text{Var}\left(#1\right)}
\newcommand{\mc}[3]{\multicolumn{#1}{#2}{#3}}

\tikzset{
  basic/.style  = {draw, text width=2cm, drop shadow, font=\sffamily, rectangle},
  root/.style   = {basic, rounded corners=2pt, thin, align=center,
                   fill=green!30},
  level 2/.style = {basic, rounded corners=6pt, thin,align=center, fill=green!60,
                   text width=8em},
  level 3/.style = {basic, thin, align=left, fill=pink!60, text width=6.5em}
}


\newcommand\independent{\protect\mathpalette{\protect\independenT}{\perp}}
\newcommand\gamij{\mathbf{\gamma_{ij}}}
\def\independenT#1#2{\mathrel{\rlap{$#1#2$}\mkern2mu{#1#2}}}
\newcommand\params{(p_M, p_{M\ell}, p_{U\ell})}
\newcommand\longparam{(L,n_1,n_2, p_M,p_{M\ell},p_{U\ell})}


%Allows multi-column tables 
\input{./Deadlines/tcilatex}

\setlength{\topmargin}{-0.4in} 
\setlength{\textheight}{8.9in}
\setlength{\parindent}{2em}
% \setstretch{1.25}
\doublespacing
\title{\singlespacing Methods for analyzing linked data}
\author{Rachel Anderson\thanks{Mailing Address: Department of Economics, Julis Romo Rabinowitz Building,
Princeton, NJ 08544. Email: rachelsa@Princeton.edu.
This project received funding from the NIH (Grant 1 R01 HD077227-01). }}
\date{This Version: \today}

\begin{document}

\maketitle


\begin{abstract}
\singlespacing
\noindent This paper compares different methods for estimating parametric models with linked data, i.e. when $x$ and $y$ are observed in distinct datasets with imperfect identifiers.  This setup requires that the researcher must attempt to identify which observations in the $x$- and $y$-datafiles refer to the same individual, prior to performing inference about the joint or conditional distributions of $x$ and $y$.  At a minimum, random errors in the matching step introduce measurement error that must be accounted for in subsequent inference; however, additional concerns about sample selection arise when these errors are correlated with unobservables that affect $x$ or $y$.  \end{abstract}

% Using matched data requires estimation techniques that incorporate information from the matching process to improve efficiency and accurately reflect uncertainty. 

\newpage
\section{Introduction}

When analyzing multiple data sources with overlapping units, automated record linkage procedures offer the least cost solution for merging data.  These methods allow the researcher to specify a set of matching variables that are recorded across all of the datasets, and a decision rule for linking record pairs, in order to obtain a matched dataset in a matter of minutes.  When the files to be linked are large, the time saved relative to manual linking or automated linking with clerical review is immense. 

In the social sciences, interest in automated record linkage methods emerged in response to the increasing availability of administrative datasets, including recently digitized historical complete count population censuses.  Although these techniques originated in other fields -- primarily statistics, computer science, operations research, and epidemiology -- social scientists have developed their own linking methods in response to concerns about the accuracy and representativeness of data that are matched using imperfect identifiers.  

This new research agenda is driven by economic historians and historical demographers, who use data with identifiers that are prone to  typographical, duplication, enumeration, and digitization error.  Additionally, the identifiers may be misreported -- for example, ages may be rounded to integers ending with a 0 or 5 -- or repeated within a sample, as might happen if several people born in the same year have the same name.  Historical record linkage procedures primarily differ according to how they address these issues of data quality. 

Examples of this literature include recent papers by \cite{abe2019} and \cite{bailey2017}, who compare the performance of popular historical record linkage methods to datasets matched by hand-linking or to simulated ``ground truth" datasets.  Although they implement different methods, both papers document a tradeoff between the false positive rate and the (true) match rate across procedures, and seem to agree that using more conservative algorithms leads to more representative data.  

Other contributions to this literature include papers by \cite{arp2018} and \cite{enamorado2019}, who demonstrate how to apply probabilistic record linkage methods from statistics to match historical and large-scale survey data.  These methods offer an advantage over the deterministic methods studied by \cite{abe2019} and \cite{bailey2017}, in that they can quantify the uncertainty about the matched data.  Furthermore, this extra information can be used to correct for bias introduced by false matches in the Ordinary Least Squares (OLS) estimator, using methods proposed by \cite{sw1993} and \cite{lahiri05}.

The ability to use probabilistic record linkage to correct for bias in the OLS estimator illustrates how the \textit{outputs} of different matching procedures determine which estimation methods are available for subsequent analysis.  Similarly, \cite{ahl2019} develop methods for consistently estimating Generalized Method of Moments (GMM) models using linked data that include multiple matches per observation.  Unfortunately, none of these estimation methods is acknowledged in the survey papers by \cite{abe2019} and \cite{bailey2017}; however, it seems natural that the choice of which matching procedure to use should be informed by which estimation methods are available. 

% good til here

The goal of this paper is to build a bridge between the matching and estimation steps in the analysis of linked data.  I compare the performance of different methods that incorporate different types of information, as well as extend the methods from \cite{ahl2019} to incorporate probabilities as may be outputted from a record linkage procedure.  



% maybe add to intro Other methods for estimating with linked data are ad hoc or are not easily adapted to the setup in Section 2.  For example, \cite{bleakley2016} generated ``composite match" equal to the average of the linked observations.   \cite{nq2015} construct bounds on the parameter of interest using different configurations of matched data.   \cite{abe2012} use traditional estimation methods using only individuals who are uniquely matched, and then reweight on observables (not sure what this means?).   In statistics, authors have suggested using probabilistic record linkage and multiple imputation to correct for bias introduced by errors in the matching process \cite{sw1993, lahiri05, Goldstein2012}.   Multiple imputation is not useful here, as we do not consider missing data. The Lahiri methods require $N_x = N_y$ and so we are left with two methods.

By comparing the estimation methods, this gives suggestion to which record linkage procedure should be used (or, better yet, which outputs of the record linkage procedure are necessary for optimal estimation).  The main result is that unless probabilities can be estimated accurately, knowledge about them should not be incorporated in the estimation step.  

My analysis in the paper supports support the following suggestions for analyzing linked data: if you use deterministic matching, you should allow for multiple matches and use the estimator in \cite{ahl2019}.  If you use probabilistic record linkage, you should choose the match with the highest probability of being correct if it exceeds a certain threshold; otherwise you should use multiple matches because the estimated probabilities can be noisy, and can result in large weights on observations with small $\pi_{i\ell}$.  When it doubt, implement all methods and compare the results!

In order to illustrate the techniques studied in this paper, Section 2 introduces a numerical example that is used to demonstrate the matching and estimation techniques described in Sections 3 and 4.  Section 5 provides details about the implementation of the methods and data generating processes.  Section 6 contains the results, and Section 7 concludes.

%Each step of the record linkage process introduces the possibility that a true match is overlooked (Type II error), or that a false match is designated as correct (Type I error); and, generally, there is a tradeoff between reducing either one of the two \citep{abe2019, harron2018}.  Also representativeness is an issue. However, the impact of data pre-processing choices on estimation is still not well understood.  

%discussion can include where this may fail. 
%The example of \cite{aizer2016} illustrates how the choice of matching procedure determines which estimation methods are available.  Alternatively, the authors could have used probabilistic record linkage to estimate the probability that a given $(x_i, y_j)$ pair refers to a match, and incorporated this information into their estimation using the methods described in \cite{sw1993}.  

\section{Setup} 

In this section, I describe a simplified version of the estimation problem described in \cite{ahl2019}.  Whereas \cite{ahl2019} study how to incorporate multiple matches in a GMM framework, this paper focuses on estimating $\beta$ in the linear regression model, \begin{equation} y_i = x_i'\beta + \varepsilon_i, \ E[\varepsilon | x_i] = 0, \ E[\epsilon_i^2] = \sigma^2  \label{model} \end{equation}
where $x_i$ and $y_i$ are recorded in different datasets, and must be linked using auxiliary variables that are contained in both data sources.  

Formally, the data consist of observations $\{x_i, w_i\}_{i=1}^{N_x}$ in the $x$-datafile, and observations $\{y_j, w_j\}_{j=1}^{N_y}$ in the $y$-datafile.  I assume that $N_y\geq N_x$, and that every $x_i$ has a unique match in the $y$-datafile that satisfies the relationship in (\ref{model}), but the index $j$ that corresponds with the match is unknown.  Some $y_j$ may not correspond to any observation in the $x$ dataset, nor satisfy the relationship in (\ref{model}) for some unobserved $x_j$.  Hence, estimating the model in (\ref{model}) requires identifying which $(x_i,y_j)$ pairs refer to the same individuals by comparing $w_i$ and $w_j$ and designating matches according to some matching procedure. 
\addlinespace
\textbf{Example 1.}  To fix ideas, consider the work of \cite{aizer2016}, who seek to estimate the impact of providing cash transfers to single mothers on the life expectancy of their children.  The $x$-datafile consists of mothers' welfare program applications, where $x_i$ includes a binary variable equal to 1 if person $i$'s mother received a cash transfer, and other demographic variables.  The $y$-datafile is a universal database of death records, which includes $y_j$, person $j$'s age at death for all deaths reported to the Social Security Administration after 1965.  Both of the $x$- and $y$-datafiles also contain identifiers $w_i$ and $w_j$, which include first name, middle initial, last name, day, month, and year of birth, so that individuals with common names are not identified uniquely. 
\addlinespace
For the purposes of this paper, a matching procedure is defined as a set of rules used to construct a (potentially multi-valued) linking function, $\varphi: \{1,\dots, N_x\} \to \{1,\dots, N_y\} \cup \varnothing$, where $\varphi(i) = j$ if the $i$th observation in the $x$-datafile is matched to the $j$th observation in the $y$-datafile, and $\varphi(i) = \varnothing$ if $i$ is not assigned a match.  If $w_i$ and $w_j$ identify individuals uniquely and without error, then setting $\varphi(i) = j$ if and only if $w_i = w_j$, and $\varphi(i) = \varnothing$ otherwise, will correctly identify all true matches contained in the data.  In most applications, however, $w_i$ and $w_j$ cannot be used to unambiguously differentiate true matches, so that assigning $\varphi$ may include linking false matches or excluding true matches.  In this case, $\varphi$ may be constructed using estimates of $\pi_{ij}$, which denotes the probability that an $(i,j)$ pair refers to a match.  

\addlinespace
\textbf{Example 1 (cont'd).} \cite{aizer2016} construct $\varphi$ using a deterministic linking method that allows for errors in strings and dates of birth.  To account for changes in spelling and typographical errors, they convert all names into sounds using a phonetic algorithm, and measure the similarity between two individual's phonetically-spelled names using a string distance metric called SPEDIS.  They assign as matches all pairs of individuals whose birthdates fall within a predetermined range and whose SPEDIS score falls below a threshold.  Notably, their procedure does not enforce unique matches, so that some individuals are matched to multiple death records, and $\varphi$ is a correspondence. 
\addlinespace

Although I will discuss a few of the most popular methods used to construct $\varphi$ in later sections, this is not the focus of this paper.  Like \cite{ahl2019}, I take $\varphi$ and the matched dataset it produces as given.  The matched dataset can be written in the general form \begin{equation} \mathcal{D}_n \equiv \left(x_i, w_i, \{y_{i\ell}\}_{\ell=1}^{L_i}, \{\pi_{i\ell}\}_{\ell=1}^{L_i}\right)_{i=1}^N \label{data} \end{equation}
where $x_i$ is a vector of covariates for a single observation in the $x$-datafile, and $\{y_{i\ell}\}_{\ell=1}^{L_i}$ are the outcomes from the $y$-datafile to which it is linked based on the identifying variables $w_i$.  The variables $\{\pi_{i\ell}\}_{\ell=1}^{L_i}$ correspond to the conditional probability that a particular $y_{i\ell}$ refers to the correct match, so that $\sum_{\ell=1}^{L_i} \pi_{i\ell} = 1$.  If $\varphi$ was constructed without estimating $\pi_{i\ell}$, as in a deterministic matching procedure, I assume that $\pi_{i\ell} = \frac{1}{L_i}$.  

Additionally, I assume that (i) the true match $y_i$ is included among the possible matches $\{y_{i\ell}\}_{\ell=1}^{L_i}$ for all $i$, and that (ii) the observed $x_i$ and $\{y_{i\ell}\}_{\ell=1}^{L_i}$ are i.i.d. draws from their marginal distributions conditional on the identifying variables $w_i$.  Assumption (i) is necessary for identification, and Assumption (ii) is a selection on observables assumption, which requires that all individuals with the same identifying information are equally likely to be included in $\mathcal{D}_n$.  

Assumption (i) needs to be verified empirically; however the simulations in Section X suggest that it is reasonable when multiple matches are allowed.  Assumption (ii) requires thats all individuals with the same identifying information (such as name, age, Census block) have equal probability of appearing in the sample.  This assumption would be violated if, for example, higher income individuals have a greater probability of appearing in the sample (unless individuals are matched by income); but the OLS estimator using perfectly linked data would also be biased because of unobserved sample selection. 

\section{Estimation methods for linked data }

In this section, I review methods from \cite{sw1993} and \cite{ahl2019} (henceforth referred to as the SW and AHL estimators) for estimating regression models using matched data with the structure (\ref{data}), and establish conditions under which they are equivalent.   Although there are other methods for analyzing linked data, none is compatible with the setup described in Section 2.  For example, \cite{lahiri05} develop a version of the SW estimator based on the assumption that each observation in the $y$-datafile is generated by model in (\ref{model}), and that its corresponding value of $x$ appears in the $x$-datafile.  This differs from the problem considered in this paper, which allows for $N_y > N_x$, and assumes that the relationship in (\ref{model}) holds only for observations in the $x$-datafile. % Sentence about Goldstein.

\subsection{\cite{sw1993}}

Building upon the work \cite{NeterMaynes}, \cite{sw1993} study how to correct for bias introduced using incorrectly linked data in linear regression models.  Their methods assume that the data consist of observations $(x_i,z_i)_{i=1}^N$, so that each $x_i$ is linked with a single outcome $z_i$ that may or may not correspond to the true $y_i$.  Specifically, 
$$z_i = \begin{cases} y_i & \text{with probability $q_{ii}$} \\ y_j & \text{with probability $q_{ij}$ for $j\neq i,\ j = 1,\dots,N_y $} \end{cases}$$ 
and $\sum_{j=1}^{N_y} q_{ij} = 1, \ i=1,\dots, N$, where $N_y$ is the size of the $y$-datafile and $N$ is the size of the matched dataset.   Estimating (\ref{model}) using $z_i$ as the dependent variable yields the naive least squares estimator, 
\begin{equation} \hat{\beta}_N = (X'X)^{-1} X'z \label{naive} \end{equation}
which is biased, because $ E[z_i ] = E\left[q_{ii} y_i + \sum_{j\neq i} q_{ij} y_j\right] \neq E[y_i]$ if $q_{ii}\neq 1$ for some $i$.  Denoting
 $q_i = (q_{i1}, \dots, q_{iN_y})'$, \cite{sw1993} derive the bias of $\hat{\beta}_N $ conditional on the observed values of $y$,
\begin{equation} \text{bias} (\hat{\beta}_N | y) = E[(\hat{\beta}_N - \beta) | y ] = (X'X)^{-1} X'B \label{bias} \end{equation}
where $B = (B_1, \dots, B_n)'$ and $B_i = (q_{ii}-1)y_i + \sum_{j\neq i } q_{ij} y_j = q_i'y - y_i$, which is the difference between a weighted average of responses from all observations and the true response $y_i$.  

Observing (\ref{bias}), \cite{sw1993} propose estimating $\hat{B}$ using the first and second highest elements of $q_i$, and their corresponding values $y_j$ to compute 
\begin{equation} \hat{B}_i^{TR} = (q_{ij_1} - 1) y_{ij_1} + q_{ij_2} y_{ij_2} \label{bHat} \end{equation}
for each $i$, and then using it to correct for the bias in $\hat{\beta}_N$ as follows,
\begin{equation} \hat{\beta}_{SW} = \hat{\beta}_N - (X'X)^{-1} X' \hat{B}^{TR} \label{sw}\end{equation}
In principle, $\hat{B}^{TR}$ can incorporate any number of elements of $q_i$, however \cite{sw1993} show that if $q_{ij1}$ is sufficiently high for all $i$, then the truncation with two links results in a very small bias.  
 
The SW estimator has two important caveats.  The first is that it requires that the $y$ value associated with the largest element in $q_i$ corresponds with the true outcome $y_i$, so that errors in $z_i$ result from random assignment rules or requiring that no two values $x_i$ and $x_j$ are linked to the same value of $y$.  The second is that constructing $\hat{\beta}_{SW}$ requires knowledge of $q_{i}$ and the corresponding elements of $y$, and so it cannot be applied to data linked with deterministic methods.  Even if estimates of $q_{ij}$ are available, $\hat{\beta}_{SW}$ will be biased if the estimates $\widehat{q_{ij}}$ are correlated with $x$ or $y$, which occurs if $x$ or $y$ is correlated with errors in the matching variables.  This assumption is different from Assumption (ii) in Section 2, and often fails in economic application, such as in \cite{nq2015}, where $y$ measures whether a person's recorded ethnicity changes between Census years, and changes in first and last name (the matching variables) are strongly correlated with $y$.  

\subsection{\cite{ahl2019}}

Unlike the SW estimator, the estimator proposed in \cite{ahl2019} is unbiased under Assumptions (i) and (ii) from Section 2, and does not require estimates of $q_{ij}$.  Recall that the assumptions are that (i) the true match of $x_i$ is included among the matches $\{y_{i\ell}\}_{\ell=1}^{L_i}$ for all $i$, and (ii) $x_i$ and $y_i$ are random samples conditional on the matching variables.  Assumption (ii) allows $x$ and $y$ to be correlated with errors in matching, so long as that dependence is fully captured by $w$; hence the AHL estimator would be valid in the \cite{nq2015} example if ethnicity is included among the matching variables.  

The goal of \cite{ahl2019} is to estimate $\theta_0$ that satisfies the model
\begin{equation}
E_0\left[ m\left( y_{i},x_{i};\theta _{0}\right) \right] =0
\label{Moment}
\end{equation}%
where $y_{i}$ and $x_{i}$ are vectors or scalars of data for an individual $i$, the function $m(\cdot)$ is known, and the expectation is taken with respect to the joint distribution $f_0(y,x)$.  The data consist of observations $\left(x_i, w_i, \{y_{i\ell}\}_{\ell=1}^{L_i}\right)_{i=1}^N$, where the $x_i$ and $y_{i\ell}$ are recorded in distinct datasets and matched according to the identifier $w_i$.  They assume $L_i > 1$ for some $i$, so that the identity of the outcome that generates the relationship in (\ref{Moment}) is unknown.  

Under assumptions (i) and (ii) in Section 2, (\ref{Moment}) can be rewritten,
\begin{gather*}
E_0[m(y_i, x_i; \theta)] = E\left[\sum_{\ell=1}^{L_i} m(y_{i\ell}, x_i; \theta)\right] - E\left[(L_i -1)g(w_i, L_i; x_i; \theta)\right] \\ 
g(w_i, L_i, x_i; \theta) = E\left[m(y_i, x_i; \theta) |\ w_i, L_i \right] 
\end{gather*}
so if $g$ is known or can be estimated consistently, a sample version of (\ref{Moment}) can be constructed as follows,
\begin{equation}
\overline{m}_n(\theta, \hat{g}) = \frac{1}{N}\sum_{i=1}^N \sum_{\ell=1}^{L_i} m(y_{i\ell}, x_i ;\theta) - \frac{1}{N}\sum_{i=1}^N (L_i-1) \hat{g}(w_i, L_i, x_i; \theta) 
\label{ahl_moment}
\end{equation}
which is in general a two-step procedure, where $\hat{g}$ is estimated using nonparametric methods such as $k$-Nearest Neighbors or local polynomial regression in the first step.  The GMM estimator applied to (\ref{ahl_moment}) is consistent and asymptotically normal under the regularity conditions described in \cite{ahl2019}. 

For the linear regression model in (\ref{model}), the AHL estimator can be computed by applying OLS to the transformed regression model,
\begin{equation} 
\sum_{\ell=1}^{L_i} y_{i\ell} - (L_i - 1)\hat{g}(w_i, L_i) = x_i'\beta + u_i  \label{ahl} \end{equation}
where $\hat{g}(w_i,L_i)$ is a (possibly nonparametric) estimator of $E[y_{i\ell} | w_i, L_i ]$, $u_i = \varepsilon_i + \sum_{\ell=1}^{L_i}\nu_{i\ell}$, and $\nu_{i\ell} = y_{i\ell} - \hat{g}(w_i, L_i)$.   If, additionally, $E[\varepsilon_i^2 | x_i, w_i, L_i] = \sigma_{\varepsilon}^2$ and $E[\nu_{i\ell}^2 | x_i, w_i, L_i] = \sigma_{\nu}^2$ then the efficient estimator is weighted least squares,
\begin{equation}
\hat{\beta}^{WLS} = \left(\sum_{i=1}^N \frac{x_ix_i'}{\sigma(X_i)}\right)^{-1}\left(\sum_{i=1}^N \frac{x_i}{\sigma(X_i)}\left(\sum_{\ell=1}^{L_i} y_{i\ell} - (L_i - 1) g(w_i, L_i)\right)\right) \label{wls}
\end{equation}
where $\sigma(X_i) = \sigma_{\varepsilon}^2 + (L_i - 1)\sigma_{\nu}^2$.   

Unfortunately, the performance of the AHL estimator depends on the accuracy of $\hat{g}(w_i, L_i)$, which is a function of a potentially high-dimensional vector $w_i$ that may contain string or categorical variables.  However, if consider adding an assumption (iii) that $E[m(y_i, x_i; \theta) | L_i = \ell] = E_0[m(y_i, x_i; \theta)]$, then 
\begin{equation}
E_0[m(y_i, x_i; \theta)] = E\left[\sum_{\ell=1}^{L_i} m(y_{i\ell}, x_i; \theta) \Bigg|\ L_i = 2 \right]  - E\left[ \sum_{\ell=1}^{L_i} m(y_{i\ell}, x_i; \theta) \Bigg|\ L_i = 3\right] \label{new_ahl} \end{equation}
and
\begin{equation}
E_0[m(y_i, x_i; \theta)] = E[m(y_{i\ell}, x_i; \theta) | L_i =1]  \label{obs}
\end{equation}
So that we apply GMM to (\ref{new_ahl}) and (\ref{obs}) as the new moment conditions.  Applying this to the linear regression model (\ref{model}), yields the following moment conditions,
\begin{gather}
\begin{bmatrix} \frac{2}{N_{L_ 2}} \sum_{i=1}^{N_{L_2}} (y_{i1} + y_{i2} - x_i'\beta)x_i  - \frac{1}{N_{L_3}} \sum_{i=1}^{N_{L_3}} (y_{i1} + y_{i2} + y_{i3} - x_i'\beta)x_i   \\
\frac{1}{N_{L_1}}\sum_{i=1}^{N_{L_1}} (y_i - x_i'\beta)x_i \end{bmatrix} = 0 
\end{gather}
where $N_{L_{\ell}}$ is the number of observations matched to $\ell$ observations.  In practice, the precision of the estimator depends on the number of observations that are linked to two and three outcomes, however the estimator based on these moments should be asymptotically consistent.  % think about doing a proof

\subsection{Comparing $\hat{\beta}_{SW}$ and $\hat{\beta}_{AHL}$}
There is a natural parallel between $\hat{\beta}_{SW}$ and $\hat{\beta}_{AHL}$ when we consider data of the form in (\ref{data}), and we assume that $L_i$ is the number of links whose $q_{ij}$ exceed a threshold $\bar{q}$, and that the conditional probabilities $\pi_{i\ell} = \frac{q_{i\ell}}{\sum_{\ell=1}^{L_{i}} q_{i\ell}}$.  Let also $y_{i\ell^*}$ refer to the element of $\{y_{i\ell}\}_{\ell=1}^{L_i}$ that is associated with the highest value of $\{\pi_{i\ell}\}_{\ell=1}^{L_i}$.  Then, we can write $\hat{\beta}_{SW}$ as the OLS estimator for the model
\begin{equation}
z_i - \hat{B}_i = x_i'\beta + \varepsilon_i 
\label{transformed}
\end{equation}
with $\hat{B}_i = \sum_{\ell =1}^{L_i} \pi_{i\ell} y_{i\ell} - y_{i\ell^*}$.  Note that the \cite{sw1993} method assumes that the $y_{i\ell}$ with the highest value of $\pi_{i\ell}$ is the true match.\footnote{There are reasons that $z_i \neq y_{i\ell^*}$.  This happens, for example, if $z_i$ is assigned at random according to the probabilities $\pi_{i\ell}$ or if a one-to-one matching is enforced such that no single $y$ is assigned to two distinct values of $x$}

The AHL estimator can be written in the form (\ref{transformed}) with 
\begin{equation}
\hat{B}_i = z_i - \sum_{\ell=1}^{L_i} y_{i\ell} + (L_i -1) \hat{g}(w_i, L_i) \end{equation} 
so that $\hat{\beta}^{AHL}$ and $\hat{\beta}^{SW}$ differ only in their choice of $B_i$.  Alternatively, $\hat{\beta}_{SW}$ can be written in the form of $\hat{\beta}_{AHL}$, as in equation (\ref{ahl}), by setting 
\begin{equation} \hat{g}(w_i, L_i) = \frac{1}{L_i -1 }\left( \sum_{\ell \neq \ell^*} y_{i\ell} + y_{i\ell^*} \right) \label{ahl_sw} \end{equation}
Since $\hat{g}(\cdot)$ as written in (\ref{ahl_sw}) ignores information about $w_i$, and assumes that $y_{i\ell^*}$ is the correct match, the AHL estimator may perform better if $y_{i\ell^*}$ is not the true match, informative $\pi_{i\ell}$ are not available, or $w_i$ contains information about the conditional mean of the $y_{i\ell}$ drawn from the incorrect distribution.   However, if reliable estimates of $\pi_{i\ell}$ are available, it may be possible to improve the AHL estimator by incorporating this information.  I explore this possibility in the next section. 

\section{Incorporating probabilities in the AHL estimator} 

I begin by considering a simplified version of the AHL (2019) problem, based on the observation that 
$$ E[m(y_{i\ell}, x_i; \theta)] =  \begin{cases} 0 & \text{if } y_{i\ell} = y_i \\
g(w_i, L_i, x_i; \theta) & \text{if } y_{i\ell} \neq y_i
\end{cases} $$
If $\hat{g}$ can be estimated consistently, or $g(\cdot)$ is a constant function, this problem can be reduced to estimating the mean using observations $\{X_{i\ell}\}_{\ell=1}^{L_i}$, where each $X_{i\ell}$ is drawn from the correct distribution with probability $\pi_{i\ell}$ and drawn from the incorrect distribution with probability $(1-\pi_{i\ell})$.  Under Assumption (i), exactly one of the $X_{i\ell}$ is drawn from the correct distribution, so that $\sum_{\ell=1}^{L_i} X_{i\ell} = \mu + (L_i -1) \kappa$, where $\mu =0$ in the above example, and $\kappa = g(\cdot)$. 

\subsection{Estimating the mean}

Consider the problem of estimating the mean of a random variable $X \sim F_X(\mu; \sigma^2)$ using two observations $X_{1}$ and $X_{2}$.  With probability $\pi$, $X_1$ is drawn from the true distribution $F_X$ and $X_2$ is noise drawn from the distribution $F_Y(\kappa, \omega^2)$.  With probability $1-\pi$, $X_2$ is drawn from the correct distribution and $X_1$ is noise.  Under this specification, exactly one of $X_1$ or $X_2$ is drawn from the distribution of interest at all times.  

Observe that if $\pi$ is known, we can construct an unbiased estimator using only $X_1$,
\begin{equation}
\hat{\mu}_1 = \frac{X_1}{\pi} - \frac{1-\pi}{\pi} \kappa 
\label{mu1}
\end{equation} 
and, similarly, we can construct an unbiased estimator using only $X_2$,
\begin{equation}\hat{\mu_2} = \frac{X_2}{1-\pi} - \frac{\pi}{1-\pi} \kappa \label{mu2} \end{equation} 
Any unbiased linear estimator $\hat{\mu}$ that uses both $X_1$ and $X_2$ can be written as a combination of $\hat{\mu}_1$ and $\hat{\mu}_2$ (see Lemma 1 in the Appendix for a proof), so finding the minimum variance, unbiased linear estimator $\hat{\mu}$ requires minimizing 
$$\min_d\  \Var{d \hat{\mu}_1 + (1-d) \hat{\mu}_2}$$
which is solved by \begin{equation} d^*= \frac{\Var{\hat{\mu}_2} - \text{Cov}(\hat{\mu}_1, \hat{\mu}_2)}{\Var{\hat{\mu}_1} + \Var{\hat{\mu}_2} - 2 \text{Cov}(\hat{\mu}_1, \hat{\mu}_2)} \label{dOpt}\end{equation}
where
\begin{align} \Var{\hat{\mu}_1} &=  \frac{\text{Var}(X_1)}{\pi^2} = \frac{1}{\pi^2}\left(\pi \sigma^2 + (1-\pi) \omega^2 + \pi(1-\pi)(\mu-\kappa)^2\right) \label{vmu1}\\
\Var{\hat{\mu}_2} &= \frac{\Var{X_2}}{(1-\pi)^2} = \frac{1}{(1-\pi)^2}\left((1-\pi)\sigma^2 + \pi \omega^2 + \pi(1-\pi)(\mu-\kappa)^2\right)\label{vmu2} \\
\text{Cov}(\hat{\mu}_1, \hat{\mu}_2) &= \frac{\text{Cov}(X_1,X_2)}{\pi(1-\pi)} = \frac{1}{\pi(1-\pi)}\left((1-\pi^2 - (1-\pi)^2)\mu\kappa - \pi(1-\pi)(\mu^2 + \kappa^2)\right) \label{cov}
\end{align} 
Derivations of these formulas are in the appendix.

Thus, the minimum variance unbiased estimator is 
\begin{equation} \hat{\mu}^* \equiv \hat{\mu}(d^*) = d^* \hat{\mu}_1 + (1-d^*) \hat{\mu}_2 \label{muOpt}
\end{equation}
where $d^*$ is defined as in (\ref{dOpt}).  Note that $d^*$ is strictly increasing in $\pi$, but at a rate that depends on $\sigma^2, \omega^2, \mu,$ and $\kappa$.  Intuitively, this means that the optimal estimator $\hat{\mu}^*$ puts more weight on the observation that is most likely to be correct. 

Figure \ref{dStar} plots the optimal $d^*$ for $\pi\in[0,0.5]$, since the solution is symmetric in $\pi$ when $L=2$. When $\pi=0.5$, $\Var{\hat{\mu}_1}=\Var{\hat{\mu}_2}$ so that $d^*=0.5$, regardless of the other parameter values.  When the variance of both the correct and incorrect distributions are the same (i.e., $\sigma^2 = \omega^2$), then $\Var{X_1}=\Var{X_2}$, and differences in $d^*$ reflect only changes in $\pi$.   When $\sigma^2 \neq \omega^2$, the optimal $d^*$ puts additional weight (relative to the equal variance case) on the estimator based on the $X_i$ that is more likely to come from the lower variance distribution.  The curve with $\sigma^2 = 1$ and $\omega^2 = 10$ is the extreme version of this scenario, and represents what may happen if $\kappa$ is estimated imprecisely.  The resulting $d^*$ assigns very low weight to the observation that is more likely drawn from the incorrect distribution.  

\begin{figure}[htbp]
\begin{center}
\caption{Optimal $d^*$ as a function of $\pi$ and $\sigma^2, \omega^2, \mu, \kappa$}
\includegraphics[width=0.8\textwidth]{./Figures/dStar.pdf}
\label{dStar}
\end{center}
\end{figure}

More generally, the estimator $\hat{\mu}^*$ can be computed for a sample of observations $(X_{i1}, X_{i2})_{i=1}^N$, where $X_{i1}$ is drawn from $F_X$ with probability $\pi_i$, and $X_{i2}$ is drawn from $F_X$ with probability $1-\pi_i$.  In this case, $d^*$ is calculated according to (\ref{dOpt}) using,
\begin{align*} \hat{\mu}_1 &= \frac{1}{N} \sum_{i=1}^N \frac{X_{i1}}{\pi_i} - \frac{1-\pi_i}{\pi_i}\kappa 
& \Var{\hat{\mu}_1} &=  \frac{1}{N^2}\sum_{i=1}^N \frac{g(\pi_i; \theta)}{\pi_i^2} \\
 \hat{\mu}_2 &= \frac{1}{N} \sum_{i=1}^N \frac{X_{i2}}{1-\pi_i} - \frac{\pi_i}{1-\pi_i}\kappa \ &\Var{\hat{\mu}_2} &= \frac{1}{N^2} \sum_{i=1}^N \frac{g(1-\pi_i; \theta)}{(1-\pi_i)^2} \end{align*}
$$\text{Cov}(\hat{\mu}_1, \hat{\mu}_2) = \frac{1}{N^2}\sum_{i=1}^N \frac{\text{Cov}(X_{1i}, X_{2i})}{\pi_i(1-\pi_i)} $$
where $g(p; \theta) = p \sigma^2 + (1-p) \omega^2 + p(1-p)(\mu-\kappa)^2$ is the variance of $X_{i\ell},$ for $\ell \in \{1,2\}$, that has probability $p$ of being drawn from the correct distribution.  


\subsection{Errors in $\hat{\pi}$}

The construction of $\hat{\mu}^*$ was based on the assumption that $\pi$ was known; this section studies the performance of $\hat{\mu}^*$ when only an estimate $\hat{\pi}$ is available. 

Suppose that we have an i.i.d. sample of observations $(X_{i1}, X_{i2})_{i=1}^N$, where $X_{i1}$ is drawn from $F_X$ with probability $\pi$, and $X_{i2}$ is drawn from $F_X$ with probability $1-\pi$.  In the context of record linkage, $X_{i1}$ and $X_{i2}$ may refer to two possible matches for an observation, and $\pi$ is the probability that $X_{i1}$ is the true match.  The estimated probabilities $\hat{\pi}$ may be obtained from a probabilistic record linkage procedure or reflect prior knowledge about the matching application\footnote{For example, $\hat{\pi}$ may reflect the econometrician's belief that ``Alicia" is more likely than ``Alex" to refer to the true match of an individual named ``Ali".}.

As observed in \cite{ahl2019}, when $\pi$ is unknown, it is possible to construct an unbiased linear estimator of $\hat{\mu}$ by weighting all observations equally,
\begin{equation} \hat{\mu}^{AHL} =  \frac{1}{N}\sum_{i=1}^N X_{i1} + \frac{1}{N} \sum_{i=1}^N X_{i2} - \kappa \label{ahl}\end{equation}
The variance of this estimator is
\begin{equation}
\Var{\hat{\mu}^{AHL}} = \frac{\Var{X_{1i} + X_{2i}}}{N} 
\label{var_ahl}
\end{equation}
Note that $\Var{\hat{\mu}^{AHL}} = \Var{\hat{\mu}(\pi)} = \Var{\pi \hat{\mu}_1 + (1-\pi)\hat{\mu}_2}$, so that  $\Var{\hat{\mu}^{AHL}} \geq \Var{\hat{\mu}^*}$ if $\pi$ is known, with equality holding if and only if $\pi = 0.5$.  

Since $\hat{\mu}^{AHL}$ is unbiased regardless of the beliefs $\hat{\pi}$, it is interesting to study whether $\hat{\mu}^*$ continues to minimize the mean squared error when beliefs about $\pi$ are misspecified, i.e. $\hat{\pi} \neq \pi$.  Unless $\hat{\pi}=0.5$, the estimator $\hat{\mu}^*$ that uses $\hat{\mu}_1, \hat{\mu_2}$, and $d^*$ based on incorrect beliefs $\hat{\pi}$ will be biased.  For example, if $(\mu, \sigma^2, \kappa, \omega^2) = (0, 1, 1, 2)$ and $\pi=0.6$, but the econometrician believes $\hat{\pi}=0.9$, then
\begin{gather*}
\hat{\mu}_1 = \frac{1}{N} \sum_{i=1}^N \frac{X_{i1}}{\hat{\pi}} - \frac{1-\hat{\pi}}{\hat{\pi}} = \frac{1}{N} \sum_{i=1}^N \frac{10}{9} X_1 - \frac{1}{9} \\
\hat{\mu}_2 = \frac{1}{N}\sum_{i=1}^N \frac{X_2}{1-\hat{\pi}} - \frac{\hat{\pi}}{1-\hat{\pi}} =  \frac{1}{N} \sum_{i=1}^N10 X_2 - 9
\end{gather*}
both of which are biased, because $E[\hat{\mu}_1] = \frac{1}{3}$ and $E[\hat{\mu}_2] = -3$.  Similarly, using $\hat{\pi}$ instead of $\pi$ in (\ref{vmu1})-(\ref{cov}) to calculate $\Var{\hat{\mu}_1},\ \Var{\hat{\mu}_2}$, and Cov$(\hat{\mu}_1, \hat{\mu}_2)$ results in choosing $d^* = 0.987$, and Bias(${\hat{\mu}}^*) = 0.292$ and $\Var{\hat{\mu}^*} = \frac{1.94}{N}$.

By comparison, Bias($\hat{\mu}^{AHL}) =  0$ and $\Var{\hat{\mu}^{AHL}} = \frac{3}{N}$, so we can solve for $N$ such that $MSE_n(\hat{\mu}^{AHL}) < MSE_n(\hat{\mu}^*)$ for all $n \geq N$:
$$0.292^2 + \frac{1.94}{N} = \frac{3}{N} \implies N = 12.43$$ 
This example suggests that for fixed $\theta = (\mu, \sigma^2, \kappa, \omega^2)$ and $N$, we can compare the ratio of $MSE_n(\hat{\mu}^*; \theta)/MSE_n(\hat{\mu}^{AHL};\theta) $ for different values of Bias($\hat{\pi}$).  Alternatively, for a fixed value of Bias($\hat{\pi}$), we can calculate the minimum sample size $N$ such that it is more efficient to use $\hat{\mu}^{AHL}$. 

Figures 2 and 3 plot the bias and variance of $\hat{\mu}^*$ as a function of the mis-specified beliefs $\hat{\pi}$ for different values of $\theta$.  The bias is quadratic in $|\hat{\pi}-\pi|$, with zero bias at $\hat{\pi}=\pi$ and $\hat{\pi}=0.5$.  The variance of $\hat{\mu}^*$ is not minimized at $\hat{\pi}=\pi$, but at some value determined by $\sigma^2, \omega^2$, $(\mu-\kappa)^2$, and Bias$(\hat{\pi})$.  The variance term is less interesting than the bias, because $\Var{\hat{\mu}^*}\to0$ as $N\to\infty$, whereas the bias does not disappear.  

This issue is reflected in Tables 1-3, which display the ratio of the $MSE_N(\hat{\mu}^{AHL};\theta)/MSE_N(\hat{\mu}^*;\theta)$ for $N=10, 100$, and $1000$, when $\hat{\mu^*}$ is calculated for different values of $\hat{\pi}$.  Although the values in these tables are calculated for $\theta = (\mu, \sigma^2, \kappa, \omega^2) = (0,1,1,2)$ the same pattern of results appears for other parameter combinations included in the Appendix. 

Although no economist would use $N=10$ in practice, Table 1 illustrates how, even in small samples, the AHL estimator can be more efficient than $\hat{\mu}^*$ for incorrect beliefs such that $|\hat{\pi}-\pi| >  0.35$.   For $N=100$, this tolerance for error in $\hat{\pi}$ decreases to $|\hat{\pi}-\pi| >  0.15$; and, for $N=1,000$, $\hat{\mu}^*$ outperforms $\hat{\mu}^{AHL}$ only if $\hat{\pi}=\pi$.  This pattern may suggests that incorporating knowledge about $\pi$ offers potential efficiency gains for estimators applied to small samples, but that the potential gains, as well as the tolerance for errors in $\hat{\pi}$, decrease with sample size.  Whether this result holds more generally requires additional work to incorporate heterogenous $\pi_i$ and $L>2$ observations of $X_{\ell}$.  

\begin{figure}[htbp]
\begin{center}
\caption{Bias of $\hat{\mu}^*$ as a function of $\hat{\pi}$ }
\vspace{5pt}
\includegraphics[width=\textwidth]{./Figures/bias_plot.pdf}
\label{bias_plot}
\end{center}
\end{figure}

\begin{figure}[htbp]
\begin{center}
\caption{Variance of $\hat{\mu}^*$ as a function of $\hat{\pi}$ with $N=1$}
\vspace{5pt}
\includegraphics[width=\textwidth]{./Figures/var_plot.pdf}
\label{var_plot}
\end{center}
\end{figure}

\input{./Figures/compare_10.tex}
\input{./Figures/compare_100.tex}
\input{./Figures/compare_1000.tex}

\subsection{Incorporating $\pi$ in linear regression}

Suppose we have two matches $\{y_{i1}, y_{i2}\}_{i=1}^N$ for each observation.  We get the same conditions for unbiasedness of the OLS estimator if we consider using a linear combination of the $y$'s, as in the model:
\begin{equation} a_1 y_{i1} + a_2 y_{i2} - \kappa = x_i'\beta + \varepsilon_i, \ \hspace{10pt} \Var{\varepsilon | x_i } = \sigma^2  \end{equation}
Then the OLS estimator is
$$ \hat{\beta} = \left(\frac{1}{N}\sum_{i=1}^N x_i x_i'\right)^{-1} \left(\frac{1}{N}\sum_{i=1}^N x_i'(a_1 y_{i1} + a_2 y_{i2} - \kappa)\right) $$
and
\begin{align*}
E\left[\hat{\beta}\right] &= E[x_ix_i']^{-1} E[x_i'(a_1 y_{i1} + a_2 y_{i2} - \kappa] \\
&= \beta(a_1 \pi + a_2 (1-\pi)) + E[x_ix_i']^{-1}E[x_i](a_2 \pi + (1-\pi)a_1 - a_3) \kappa 
\end{align*}
Unbiasedness requires the same conditions on $a_1, a_2,$ and $a_3$ as derived in Lemma 1, i.e.
\begin{align*}
a_2(a_1) &=  \frac{1-\pi a_1}{1-\pi} \\ a_3(a_1) &= \frac{\pi}{1-\pi} + \frac{a_1 - 2\pi a_1}{1-\pi} 
\end{align*}
which means that any unbiased linear estimator $\hat{\beta}$ can be written as a linear combination of unbiased estimators that use only $y_{i1}$ or $y_{i2}$,
\begin{align*}
\hat{\beta}_{1} &= \left(\frac{1}{N}\sum_{i=1}^N x_i x_i'\right)^{-1}\frac{1}{N}\sum_{i=1}^N \frac{x_i y_{i1}}{\pi} - \frac{1-\pi}{\pi}\kappa \\
 \hat{\beta}_{2} &= \left(\frac{1}{N}\sum_{i=1}^N x_i x_i'\right)^{-1}\frac{1}{N}\sum_{i=1}^N \frac{x_i y_{i2}}{1-\pi} - \frac{\pi}{1-\pi}\kappa 
 \end{align*}
 and so the minimum variance estimator is $\hat{\beta}^* = d^* \hat{\beta}_1 + (1-d^*)\hat{\beta}_2$, where 
 \begin{equation}
 d^* = \frac{\Var{\hat{\beta}_{2}} - \text{Cov}\left(\hat{\beta}_1, \hat{\beta}_2\right)}{\Var{\hat{\beta}_1} + \Var{\hat{\beta}_{2}} - 2 \text{Cov}\left(\hat{\beta}_1, \hat{\beta}_2\right)}
 \end{equation}
and we can repeat the exercise in the previous sections, comparing variance and bias for misspecified beliefs $\hat{\pi}$ and different parameter combinations.  The choice of the weights $d^*$ that give the optimal $\hat{\beta}^*$ is now complicated by the fact that it depends on the second moments of $X_i$, however the formulas for $\Var{\hat{\beta}_i}$ are the same as in (\ref{vmu1})-(\ref{cov}), but replacing $\mu, \sigma^2, \kappa,$ and $\omega^2$ with (under conditional homoskedasticity),
\begin{align*}
\tilde{\mu} &= \beta \\
\tilde{\sigma}^2 &=  \sigma^2 E[x_ix_i]^{-1}\\
\tilde{\kappa} &= E[x_ix_i']^{-1}E[x_i]\kappa \\
\tilde{\omega}^2 &= (\omega^2 + \kappa^2)E[x_ix_i']^{-1}
\end{align*}
and the bias and variance should behave as in Figures \ref{bias_plot} and \ref{var_plot} for misspecified beliefs $\hat{\pi} \neq \pi$.
 
\subsection{Generalizing results to $L_i > 2$}

Lemma 2 in the Appendix demonstrates that any unbiased linear estimator that uses observations $\{X_{\ell}\}_{\ell=1}^L$ can be written as linear combination of the unbiased linear estimators that use a single observation $X_{\ell}$.  This suggests that for a sample of observations $\{X_{i\ell}\}_{\ell=1}^{L_i}$, $i=1,\dots,N$, we can construct for each $i$ a minimum variance estimator 
$$\hat{\mu}_i^* = \sum_{\ell=1}^{L_i} d_{i\ell}^* \hat{\mu}_{i\ell}$$
where 
$$\hat{\mu}_{i\ell} = \frac{X_{i\ell}}{\pi_{i\ell}} - \frac{1-\pi_{i\ell}}{\pi_{i\ell}}\kappa $$ 
and construct 
$$\hat{\mu}^* = \sum_{i=1}^N \hat{\mu}_i^*}

% to do -- proof 

\section{Monte Carlo Study}

In order to compare how these methods perform in practice, I conduct a Monte Carlo study where each replication consists of (i) generating an $x$- and $y$-datafile, (ii) linking the $x$- and $y$-datafiles to obtain matched data of the form (\ref{data}), and (iii) estimating (\ref{model}) using the matched datasets and the techniques described in Sections 3 and 4.  Since the performance of the estimators depends on whether multiple matches or estimated probabilities are available, Step (ii) involves applying four record linkage procedures, each of which outputs a distinct dataset.  The remainder of this section describes in detail how I generate data for a single replication of the Monte Carlo study, with a special focus on the record linkage procedures implemented in Step (ii).  

\subsection{Generating the $x$- and $y$-datafiles}

I begin by constructing a ``ground truth" dataset with 1000 observations of $(x_{1i}, x_{2i}, y_i, w_i)$, where $x_{1i}$ and $x_{2i}$ are mutually independent, i.i.d draws from Bernoulli(0.5) and Normal(0,2) distributions, respectively.s  The $y_i$ values are generated according to \begin{gather}
y_i = \beta_0 + \beta_1 x_{1i} + \beta_2 x_{2i} + \varepsilon_i, \hspace{10pt} 
\varepsilon_i\  |\  x_{1i}, x_{2i} \overset{i.i.d}{\sim} \mathcal{N}(0, \sigma^2) 
\end{gather}
where $\varepsilon_i$ are independent draws from a Normal(0,2) distribution.  I chooses $(\beta_0, \beta_1, \beta_2, \sigma^2) = (2, 0.5, 1, 2)$, so that estimating the correctly specified linear regression model yields an $R^2$ value of approximately 0.50.  

The vector of identifying variables, $w_i$, includes a first name, last name, and birth year.  In total, there are 960 unique first and last name combinations, so multiple observations will be assigned the same first and last name.  The birth years are drawn at random from a uniform distribution over the set of integers between 1900 and 1925.  The resulting dataset resembles the top panel of Figure \ref{sample_dta}.  
 
 \input{./Figures/synthetic.tex}
 
Next, I split the ground truth dataset into the $x$- and $y$-datafiles, as in the bottom panel of Figure \ref{sample_dta}.  The $x$-datafile contains values of $(x_{i1},x_{i2})$ for 500 observations selected at random from the ground truth dataset.  The identifiers in the $x$-datafile are equal to the original $w_i$ plus some random transcription error.  The probability of introducing a certain type ofs typographical error is equal to that reported for the 1940 Census data in \cite{abe2019}\footnote{For example, 7\% of observations have misreported first names and 17\% of observations have misreported last names.} These errors include deleting characters (e.g., ``Anderson"  becomes ``Andersn"), exchanging vowels (e.g., ``Rachel" becomes ``Rachal"), and swapping English phonetic equivalents (e.g. ``Ellie" becomes ``Elie").  For half of the observations, I introduce random errors in the birth year drawn from a Normal(0, 2.5) distribution and rounded to the nearest integer.  

The $y$-datafile includes all 1,000 values of $y_i$ from the ground truth data, along with the original identifiers $w_i$.  The aim of this construction is to make it likely that some observations in the $x$-datafile will be linked to multiple values of $y$.  The next section describes the record linkage methods used to link the $x$- and $y$-datafiles. 

\subsection{Linking the $x$- and $y$-datafiles}
Taking the $x$- and $y$-datafiles as given, I implement four record linkage procedures to obtain matched datasets with the general structure in (\ref{data}).  These procedures, and their respective outputs, are summarized in Table \ref{overview}.  This section offers a brief overview of these methods, however the interested reader should refer to \cite{harron_book, christen2012} and \cite{herzog07} to learn more about modern record linkage methods. 

\input{./Figures/overview_tab.tex}

For the purposes of this paper, I define a record linkage procedure as a set of decisions about (i) selecting and standardizing the identifying variables in $w_i$ and $w_j$, (ii) choosing which $(i,j)$ pairs to consider as potential matches, (iii) defining how to measure (partial) agreement between $(w_i,w_j)$, and (iv) designating $(i,j)$ pairs as matches.  

Step (i) accounts for differences in $w_i$ and $w_j$ that arise as a result of transcription error or misreporting, even when observations $i$ and $j$ refer to the same individual.   In practice, the researcher may define binary matching variables that correspond with events such as $i$ and $j$ were born in the same month or $i$ and $j$ have last names ending with the same three characters.  If the matching variables include full strings, then the researcher may standardize them by removing spaces and non-alphabetic characters, replacing common nicknames with full names, or pre-processing names with phonetic algorithms to account for possible misspellings.

\addlinespace
\textbf{Example 2.}  The identifiers in the simulated data do not include non-alphabetic characters, but do include misspelled names, so I pre-process all of the first and last names using the New York State Identification and Intelligence (NYSIIS) phonetic algorithm, and include these phonetically-spelled names among the matching variables.  The other matching variable is birth year, which does not require standardization.   Other popular phonetic algorithms include Soundex\footnote{This is the phonetic algorithm used in \cite{aizer2016} from Example 1.} and Metafone; however, I assume that the NYSIIS algorithm performs sufficiently well for the purposes of my analysis, given that the names I use are selected from among the most common names assigned at birth in the present-day United States.  
\addlinespace

Step (ii) reduces the computational burden of a matching procedure when $N_x \times N_y$ is large, by dividing observations into non-overlapping ``blocks" based on their values of $w_i$ or $w_j$.  Only pairs assigned to the same block are considered as potential matches, and pairs that belong to different blocks are automatically designated as non-matches.  Thus, blocking variables should be recorded with minimal error, otherwise blocking can increase the Type II error rate. 

\addlinespace
\textbf{Example 2 (cont'd).} Given the size of my simulated datafiles, I do not need to impose any blocking rule for computational feasibility; however, the age-band threshold imposed by my deterministic matching methods acts as one.  These methods require that potential matches have recorded birth years that lie within a 2-year band.  Since I generate errors in the recorded birth year by rounding independent, random draws from a Normal(0, 2.5) distribution to the nearest integer, about 12 percent of these errors should result in true matches outside the threshold.  Furthermore, only half of the observations in the $x$-datafile contain errors in their recorded birth year, so this blocking structure should imply a Type II error rate of about 6 percent.  Out of the 500 observations in the $x$-datafile, this corresponds to approximately 28 false non-matches. 
\addlinespace

Step (iii) defines a metric for quantifying the similarity between non-numeric variables, such as the Jaro-Winkler distance or Levenshtein ``edit" distance for strings.  This allows the researcher to declare as a ``name match", or ``partial name match" any observation pair whose string distance is lower than a pre-specified threshold.  These metrics are related to, but different from the standardization methods described in Step (ii).  This is pointed out by \cite{arp2018}, who observe that ``Abramtziky" is coded differently than ``Abramitzky" using the NYSIIS algorithm, but the Jaro-Winkler distance between these two names is very low (0.02, where the minimum distance is 0, and the maximum distance is 1).  Also, ``James Tennes" and ``James Thomas" have the same NYSIIS code, but the Jaro-Winkler distance between ``Tennes" and ``Thomas" is 0.4 

\addlinespace
\textbf{Example 2 (cont'd).}  The probabilistic record linkage methods in this paper use Jaro-Winkler distances to calculate the similarity between strings.  This metric gives higher weight to discrepancies in the first part of the string, as this is where errors are less likely to be made when recording names \citep{jaro, winkler06}.  The Jaro-Winkler distance is also the default string metric for many record linkage packages, so this choice best reflects how researchers often match datasets in practice. 
\addlinespace

% TO DO: flesh this out probably. 
Whereas Steps (i)-(iii) involve decisions about pre-processing data that can be incorporated in any linkage procedure, Step (iv) is where the most meaningful differences among procedures arise.  The decision to match an $(i,j)$ pair requires trading off the possibility of introducing Type I or Type II error.  Probabilistic methods developed by \cite{fellegi69} show how to construct the optimal linkage rule subject to pre-specified tolerances for Type I and Type II errors.  Deterministic methods offer a proxy for these methods.   The rest of this section is devoted to discussing each method in detail.

\subsubsection{Deterministic Methods}
The deterministic matching methods used in this paper are based upon those used by \cite{abe2012, abe2014, abe2019b}, and \cite{ferrie96}; hence, I refer to my adaptations of their methods as ABE Single and ABE Multi.   The names refer to the fact that ABE Single matches each observation in the $x$-datafile to at most one observation in the $y$-datafile, and discards any observations that result in multiple matches.  By contrast, ABE Multi designates as a match \textit{any} pair of observations that have the same phonetically spelled first and last names, and whose birth years fall within a 2-year band, which can result in linking a single observation to multiple matches. 

The algorithm for ABE Single is as follows, 
\begin{enumerate}
\item Use the NYSIIS phonetic algorithm to obtain phonetically-spelled versions of the names in the $x$- and $y$-datafiles.
\item Restrict the sample to people in the $x$-datafile with unique first name, last name, birth year, and $x_{i}$ combinations. 
\item For each record $i$ in the $x$-datafile, search for a record $j$ in the $y$-datafile whose phonetically spelled first and last names and birth year match exactly.  
\begin{enumerate}
\item If there is a \textit{unique} match, designate $(i,j)$ as a match, and stop searching for additional possible matches. 
\item If there are multiple possible matches in the $y$-datafile, discard the observation $i$.
\item If there are no observations in the $y$-datafile that match $i$'s exact year of birth, search for a match within $\pm$1 year of $i$'s reported birth year; and, if this is unsuccessful, search for a match within $\pm$2 years.  If $i$ matches to multiple observations at any point, or if none of these attempts produces an exact name match, then discard the observation.
\end{enumerate}
\item Repeat Steps 2 and 3 for each record in the $y$-datafile, searching for matches in the $x$-datafile.  
\item Return the matched dataset equal to the intersection of the two sets of matches produced by Steps 3 and 4. 
\end{enumerate}
I implement ABE Multi in exactly the same way, except that I replace Step 3 with,
\begin{enumerate}
\item[3.$^*$] Designate as a match any observation in the $y$-datafile that matches $i$'s phonetically spelled first and last name exactly, and whose birth year falls within $\pm$2 years of $i$'s birth year. 
\end{enumerate}

%TO DO: Place for an example.  Replacing 3 with 3^* results in differences such as:   X Y Z? 

Although there are many variations of the ABE algorithm, such as using a $\pm5$-year age band, replacing NYSIIS with another phonetic algorithm, or allowing for partial string agreement by incorporating Jaro-Winkler string distances, I design my methods to mimic the ``basic structure" of the ABE algorithms presented in \cite{abe2019}.   As discussed above, I predict that the choice of the 2-year age band, combined with my data generation process, will result in a Type II error rate of about 5.7 percent for both the ABE Single and ABE Multi methods.  However, the focus of this paper is to study estimation methods for linked data, so I favor simplicity over choosing the optimal variant, and defer to \cite{bailey2017} and \cite{abe2019} for a discussion of these matters.  

\subsection{Probabilistic Method}

The key insight of the canonical probabilistic record linkage framework from \cite{fellegi69} is to view record linkage as a classification problem, where each $(i,j)$ record pair belongs either to the set of matches $(M)$, or non-matches $(U)$.  If the pairs are evaluated according to $K$,  comparison criteria, represented as a \textit{comparison vector}, $$\mathbf{\gamma_{ij}}= (\gamma_{ij}^1, \dots, \gamma_{ij}^{k}, \dots, \gamma_{ij}^K)$$ then the probability of observing a particular configuration of $\gamij$ can be represented by the mixture distribution:
\begin{equation}
P(\gamij) = P(\gamij | M) p_M + P(\gamij | U) p_U 
\label{mm}
\end{equation}
where $P(\gamij | M)$ and $P(\gamij | U)$ are the probabilities of observing the pattern $\gamij$ conditional on the record pair $(i,j)$ belonging to $M$ or $U$, and $p_M$ and $p_U = 1-p_M$ are the marginal probabilities of observing a matched or unmatched pair. 

Using Bayes' Rule, we can write the probability of $(i,j)$ belonging to $M$ or $U$, conditional on observing $\gamij$, as
\begin{align} P(M | \gamij) &= \frac{p_M P(\gamij | M)}{P(\gamij)} \\ 
P(U | \gamij) &= \frac{p_U P(\gamij | U)}{P(\gamij)}
 \end{align}
If we can estimate the parameters of the mixture distribution in (\ref{mm}), then we can estimate the probability that any two records refer to the same entity using the formulas above.  These probabilities can in turn be used to designate pairs as matches, or to quantify uncertainty about the matched dataset.  

In the context of this paper, the comparison vector $\gamij$ reflects agreements between $w_i$ and $w_j$, such as ``$i$ and $j$ have the same birth year" or ``$i$ and $j$ have the same phonetically spelled last name."  Yet even if all of the $\gamma_{ij}^{k}$ are binary, $\gamij$ has $2^K -1$ possible configurations of $\gamij$, and so it is convenient to assume the comparison fields $\gamma_{ij}^{k}$ are independent across $k$ conditional on match status.  This reduces the number of parameters necessary to describe each mixture class, since we can factor 
 \begin{equation} 
 P(\gamma_{ij} | C) = \prod_{k=1}^K P(\gamma_{ij}^{k} | C)^{\gamma_{ij}^{k}}(1-Pr(\gamma_{ij}^{k} | C))^{1-\gamma_{ij}^{k}} \hspace{20pt} C\in \{M, U\} 
 \label{eq:condInd}
 \end{equation}
In principle, this assumption can be relaxed using log-linear models, as in \cite{larsen_rubin_2001}; however, the conditional independence assumption is appropriate for my application, because I generate the errors for different categories of $w_i$ independently. 
 
Since membership to $M$ or $U$ is not observed, \cite{larsen_rubin_2001} suggest using the expectation-maximization (EM) algorithm from \cite{em} to simultaneously estimate the parameters in (\ref{mm}) and classify record pairs as matches or non-matches.  I use a variation of these methods developed by \cite{enamorado2019}, whose \texttt{R} package called fastLink is designed for large-scale administrative data.  Their software allows the user set a lower bound for the posterior probability of a match that will be accepted, and to decide whether unique matches should be assigned via the linear sum assignment program described in \cite{enamorado2019}.  



In my implementation of their algorithm, I set the threshold equal to 0.7, enforce the unique matches to obtain PRL Single and accept all matches with posterior probability exceeding the threshold for PRL Multi.  
note that the posterior probabilities do not sum to 1 for any indvidiual $i$, so that multiple matches are possible 

\section{Monte Carlo Study}

Following the same procedure for simulating the empirical example described in Section 2, I generate 1,000 random $x$- and $y$- dataset pairs.  I implement four types of matching procedures using each dataset pair: (i) deterministic matching with unique matches (ABE Single), (ii) deterministic matching with multiple matches (ABE Multi), (iii) probabilistic matching with unique matches (PRL Single), and (iv) probabilistic matching with multiple matches (PRL Multi).  Allowing for multiple matches means that a single observation in the $x$- datafile may be matched to multiple observations in the $y$-datafile.  

Each matching method produces a distinct matched dataset, so that the matching step produces a total of 4,000 linked datasets.  Using each of the linked datasets, I then compute (i) naive OLS estimator (using all observations and also with observations assigned $(L_i=1)$, (ii) the \cite{sw1993} bias-corrected estimator, and (iii)  the AHL estimator that assigns equal weights to multiple matches.  As a benchmark, I also compute the OLS estimator that uses only the correctly matched pairs produced by the matching algorithm, and the OLS estimator applied to all 500 correctly linked record pairs.  Details on the implementation of these algorithms and estimation procedures can be found in the appendix.  

% Match Rate Table 

\begin{table}[htbp]
\let\center\empty
\let\endcenter\relax
\centering
\caption{Summary of matching algorithm performance}
\vspace{10pt}
\resizebox{\textwidth}{!}{\input{./Figures/match_rates.tex}}
\label{match_rate}
\end{table}

\begin{table}[htbp]
\let\center\empty
\let\endcenter\relax
\centering
\caption{Performance of multiple match methods by value of $L_i$}
\vspace{10pt}
\resizebox{\textwidth}{!}{\input{./Figures/multi_tab.tex}}
\label{multi_L}
\end{table}

\subsection{Matching results}
To evaluate the matching procedures, I compute the following statistics for each linked dataset, reported in Table \ref{match_rate}:

\begin{itemize}
\item the proportion of observations in the $x$-datafile that are linked to at least one observation in the $y$-datafile (match rate), 
\item the total number of links made by the matching algorithm, 
\item the proportion of links that are incorrect (Type I error rate), 
\item the proportion of correct $(x,y)$ links that are not found by the matching algorithm (Type II error rate), 
\item the proportion of observations whose links include the true match
\end{itemize}

\noindent For the linked datasets that contain multiple matches per observation, I report also the average number of links per observation, and how often those links include the true match (Table \ref{multi_L}). 

%  Match Rate Histograms 
\begin{figure}[htbp]
\begin{center}
\caption{Match Rates by Linking Procedure } 
\includegraphics[width=0.9\textwidth]{./Figures/match_rate.pdf}
\label{match_hist}
\end{center}
\end{figure}

As seen in Table \ref{match_rate}, the average match rates range between 71 and 79 percent across the various matching procedures, but plotting the distribution of match rates in Figure \ref{match_hist} shows that ABE Multi consistently matches more observations than any other procedure.  PRL Single and PRL Multi have about the same match rate, which suggests that allowing for multiple matches adds additional matches per observations rather than matching new individuals (however, this may be an artifact of how my PRL implementation).  ABE Multi, on the other hand, seems to increase match rates by matching new observations relative to ABE Single.  

When comparing Type I error rates, it is important to note that multiple-match methods will produce more false links by construction.  Therefore, it is best to compare multi-match methods by measuring the proportion of observations whose  matches contain the true link.  In this metric, both ABE Multi and PRL Multi perform very well.  Furthermore, we can compute these values for each value of $L_i$, as in Table \ref{multi_L}, which shows that allowing multiple matches improves the accuracy of the ABE algorithm.  Table \ref{multi_L} also shows that ABE Multi and PRL Multi rarely assign more than three matches to any given observation.  

Comparing ABE Single and PRL Single in Table \ref{match_rate}, demonstrates the  usual tradeoff between Type I and Type II errors.  ABE Single is more conservative, produces incorrect matches only 3 percent of the time, but failing to identify 26 percent of all matches.  PRL Single is less conservative, missing only 15 percent of matches, but at the cost of matching false links 11 percent of the time.    

Based on these results, ABE Multi seems to perform well if multiple matches are desired.  The linked datasets produced by ABE Multi are very likely to include the true match, which is required for all of the estimation methods described in this paper.  It is also easier in terms of computation, because it does not require linear sum assignment programs or thresholds to determine which record pairs should be designated as matches.  

\subsection{Estimation Results}

I compare the estimators according to median absolute deviation, and plot histograms of the estimated values in Figures \ref{olstrue}-\ref{ols}.  In implementing the AHL (2019) estimator, I set $\hat{g}(w_i, L_i) = \sum_{j=1}^{N_y} y_j $, the mean of all $y$ observations, to reduce the computational burden and because I have generated $y$ such that it is independent of the identifiers $w_i$.  The AHL estimator will probably perform better in scenarios where $w_i$ has predictive power in estimating the conditional mean of $y_i$.   



\begin{table}[h!]
\let\center\empty
\let\endcenter\relax
\centering
\caption{Median Absolute Deviations for Estimators}
\vspace{10pt}
\resizebox{0.9\textwidth}{!}{\input{./Figures/est_tab.tex}}
\label{multi_tab}
\end{table}

\begin{figure}[htbp]
\begin{center}
\caption{Comparing OLS with true matches produced by matching algorithm vs. matches with L=1}
\includegraphics[width=1.1\textwidth]{./Figures/compare.pdf}
\label{olstrue}
\end{center}
\end{figure}


\section{Discussion/Conclusion}
To what extent my results generalize beyond the simulated data is unclear, as I made many arbitrary choices while generating the synthetic data -- such as the dictionary of names and the structure of the typographical errors that I introduce in the $x$-datafile -- that may impact my results in important ways.  However, my theoretical results suggest that (i) using the match that is most likely to be correct, and bias correcting based on the probability that it is correct is optimal, (ii) if weights are estimated imprecisely, or if no match has a high probability of being correct, then the it is better to assign equal weights to multiple matches.   This result needs to be studied using more general models, and ideally applied to real data.




% distribution of estimators
\begin{figure}[htbp]
\label{ahl_hist}
\begin{center}
\includegraphics[width=\textwidth]{./Figures/ahl_hist.pdf}
\label{ahl}
\end{center}
\end{figure}

\begin{figure}[htbp]
\label{sw_hist}
\begin{center}
\includegraphics[width=\textwidth]{./Figures/sw_hist.pdf}
\label{sw}
\end{center}
\end{figure}


\begin{figure}[htbp]
\label{ols_hist}
\begin{center}
\includegraphics[width=\textwidth]{./Figures/OLS(L=1)_hist.pdf}
\label{ols}
\end{center}
\end{figure}


\newpage



\section{Appendix}

\subsection{Proofs}
\noindent \textit{\textbf{Lemma 1.}} Any linear unbiased estimator of $\mu$ of the form
\begin{equation}
\hat{\mu} = a_1X_{1} + a_2 X_2 -  a_3 \kappa \label{mu} \end{equation}
with $a_1$ and $a_2 >0$, can be written as a linear combination of 
\begin{align*}
\hat{\mu}_1 &= \frac{X_1}{\pi} - \frac{1-\pi}{\pi} \kappa \\
\hat{\mu}_2 &= \frac{X_2}{1-\pi} - \frac{\pi}{1-\pi}\kappa 
\end{align*}
\textbf{Proof.} The expectation of $\hat{\mu}$ is 
$$ E[\hat{\mu}] = (a_1 \pi + a_2 (1-\pi))\mu + (a_1(1-\pi)+a_2\pi - a_3)\kappa $$
so that unbiasedness requires choosing $a_1, a_2$ and $a_3$ that satsify,
\begin{gather}
    a_1\pi + a_2(1-\pi) = 1 \implies a_2(a_1) = \frac{1}{1-\pi} - \frac{a_1 \pi}{1-\pi} \\
    a_1 (1-\pi) + a_2 \pi = a_3 \implies a_3(a_1) = \frac{\pi}{1-\pi}  + \frac{a_1 - 2a_1 \pi}{1-\pi} 
\end{gather}
Rewriting $\hat{\mu}$ as a function of $a_1$,  
 $$\hat{\mu}(a_1) = a_1 X_1 +  \left(\frac{1}{1-\pi} - \frac{a_1 \pi}{1-\pi}\right)  X_2 - \left(\frac{\pi}{1-\pi} + \frac{a_1 - 2a_1\pi}{1-\pi}\right)\kappa $$ 
which, after some rearranging, can be written as
$$\hat{\mu}(a_1) = (a_1 \pi) \hat{\mu}_1 + (1-a_1\pi) \hat{\mu}_2 $$
which completes the proof.  

\noindent \textit{\textbf{Lemma 2.}} Suppose the data consist of $\{X_{\ell}\}_{\ell=1}^{L}$, where each $X_{\ell}$ is drawn from the correct distribution with probability $\pi_{\ell}$ and from the incorrect distribution with probability $1-\pi_{\ell}$, and exactly one $X_{\ell}$ is drawn from the correct distribution.  Then, any unbiased estimator of $\mu$ that places positive weight on all of the $\{X_{\ell}\}$ can be written as a linear combination of $\hat{\mu}_{\ell}$, the unbiased estimator of $\mu$ that only uses $X_{\ell}$, 
$$ \hat{\mu}_{\ell} = \frac{X_{\ell}}{\pi_{\ell}}  - \frac{1-\pi_{\ell}}{\pi_{\ell}} \kappa, \hspace{10pt} \ell = 1, \dots, L $$
\textbf{Proof.}  The proof follows by induction.  Lemma 1 proves the base case for $L=2$.  Assume that $\hat{\mu}^{(L-1)} = \sum_{\ell=1}^{L-1} b_{\ell} \hat{\mu}_{\ell}$.  Construct $\hat{\mu}^{(L)} = a_1 \hat{\mu}^{(L-1)} + a_2 X_L - a_0 \kappa$, so that
$$ E[\hat{\mu}^{(L)}] = (a_1 + a_2 \pi_L) \mu + (a_2(1-\pi_L) - a_0) \kappa $$
Unbiasedness requires that
\begin{align*}
a_2(a_1) &=  \frac{1-a_1}{\pi_L} \\ 
a_3(a_1) &= \left(\frac{1-\pi_L}{\pi_L}\right)\left(\frac{1-a_1}{\pi_L}\right)
\end{align*}
Plugging this into $\hat{\mu}^{(L)}$ yields,
\begin{align*} \hat{\mu}^{(L)} &= a_1 \hat{\mu}^{(L-1)} + (1-a_1)\underbrace{\left(\frac{X_L}{\pi_L} - \frac{1-\pi_L}{\pi_L}\right)}_{\hat{\mu}_L} \\
\implies \hat{\mu}^{(L)} &= \sum_{\ell=1}^{L-1} a_1 {b_\ell} \hat{\mu}_{\ell} + (1 - a_1) \hat{\mu}_{\ell}
\end{align*}
which completes the proof.  

\subsection{Variance formulas}
$\Var{X_1}$ and $\Var{X_2}$ are calculated using the law of total variance, using the random variable $D = 1$ if $X_1$ is drawn from the correct distribution (and $X_2$ is drawn from the incorrect distribution), and $D=0$ otherwise:
\begin{align*} \Var{X_1} &= E[\Var{X_1 | D}] + \Var{E[X_1| D]} \\ 
&= P(D=1)\sigma^2 +  P(D=0)\omega^2 + \Var{\mu D + \kappa (1-D)} \\
&= \pi \sigma^2 + (1-\pi) \omega^2 + \pi(1-\pi)(\mu-\kappa)^2
\end{align*}
The same trick can be applied to calculate $\Var{X_2}$

\subsection{Variance of alternative AHL estimator}

\begin{align*}
\Var{\frac{2}{N_{L_2}} \sum_{i=1}^{N_{L_2}} (y_{i1} + y_{i2} - x_i'\beta) x_i \Bigg\vert L_i = 2} &= \frac{4}{N_{L_2}}\left(\Var{x_i\varepsilon_i | L_i = 2} + E[x_i^2 | L_i = 2](\omega^2 + \kappa^2) - E[x_i | L_i = 2 ] \kappa\right) \\
\Var{\frac{1}{N_{L_3}} \sum_{i=1}^{N_{L_3}} (y_{i1} + y_{i2} + y_{i3} - x_i'\beta) x_i \Bigg\vert L_i = 3} &= \frac{1}{N_{L_3}} \left(\Var{x_i\varepsilon_i | L_i = 3} + 2\left(E[x_i^2 | L_i = 3](\omega^2 + \kappa^2) - E[x_i | L_i = 3] \kappa \right)\right) \end{align*}


\subsection{implementation notes}

Let's talk about what I need to include here.  Here are some ideas:

Formulas for SE of SW estimator.

Details about implementation of fastLink algorithm. Also
\begin{itemize}
\item what threshold level I use for the fastLink algorithm (0.6)
\item what nonparametric technique I use for AHL (nearest neighbor) 
\item how I choose z in LL when there are multiple matches (randomly)
\item how I calculate standard errors for all of the estimators (using formulas for now)
\item how I standardize the variables for matching (nysiis function in R)
\item I change Step 2 in the ABE algorithm to restrict the all observations with unique first name, last name, date of birth, and $(x_1, x_2)$ combinations. 
\item  When allowing for multiple matches, I count as matches all record pairs with the same name, and the difference in recorded birth years is within two (or five) years.  That is, I designate all potential matches that arise in Step 3 as matches. 
\end{itemize}



%\section{More MSE Tables}

%\input{./Figures/compare_1.tex}
%\input{./Figures/compare_2.tex}
%\input{./Figures/compare_3.tex}
%\input{./Figures/compare_4.tex}
%\input{./Figures/compare_5.tex}






\newpage
\singlespacing
\bibliography{./Deadlines/proposal_bib} 
\bibliographystyle{aer}

\end{document}