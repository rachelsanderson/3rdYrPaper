\documentclass[12pt]{article}
\usepackage[margin=0.1in]{geometry}
\usepackage{xcolor}
\usepackage{framed}
\usepackage{enumitem}
\usepackage{adjustbox}
\usepackage{natbib}
\usepackage{chngpage}
\usepackage{mathtools,xparse}
\usepackage{graphics}
\usepackage{tikz}
\usepackage{tabu}
\usepackage{tikz-cd}
\colorlet{shadecolor}{orange!15}
% \definecolor{shadecolor}{rgb}{255,128,0}\
\usepackage{float}
\usepackage{fullpage} % Package to use full page
\usepackage{parskip} % Package to tweak paragraph skipping
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{hyperref}
\usepackage{pdflscape}
\usepackage{setspace}
\usepackage{graphicx} % Allows including images
\usepackage{booktabs} % Allows the use of \toprule, \midrule and \bottomrule in tables
\usepackage{longtable}
\usepackage{indentfirst}
\usetikzlibrary{arrows,shapes,positioning,shadows,trees}
\usepackage{array}
\usepackage{wrapfig}
\usepackage{multirow}
\usepackage{pdflscape}
\usepackage{threeparttable}
\usepackage{makecell}
\usepackage[normalem]{ulem}
\newcommand{\PreserveBackslash}[1]{\let\temp=\\#1\let\\=\temp}
\newcolumntype{L}[1]{>{\PreserveBackslash\raggedright}m{#1}}
\newcolumntype{R}[1]{>{\PreserveBackslash}p{#1}}
\newcolumntype{C}[1]{>{\PreserveBackslash\centering}m{#1}}

\newcommand{\mc}[3]{\multicolumn{#1}{#2}{#3}}

\tikzset{
  basic/.style  = {draw, text width=2cm, drop shadow, font=\sffamily, rectangle},
  root/.style   = {basic, rounded corners=2pt, thin, align=center,
                   fill=green!30},
  level 2/.style = {basic, rounded corners=6pt, thin,align=center, fill=green!60,
                   text width=8em},
  level 3/.style = {basic, thin, align=left, fill=pink!60, text width=6.5em}
}


\newcommand\independent{\protect\mathpalette{\protect\independenT}{\perp}}
\newcommand\gamij{\mathbf{\gamma_{ij}}}
\def\independenT#1#2{\mathrel{\rlap{$#1#2$}\mkern2mu{#1#2}}}
\newcommand\params{(p_M, p_{M\ell}, p_{U\ell})}
\newcommand\longparam{(L,n_1,n_2, p_M,p_{M\ell},p_{U\ell})}


%Allows multi-column tables 
\input{./Deadlines/tcilatex}

\setlength{\topmargin}{-0.4in} 
\setlength{\textheight}{8.9in}
\setlength{\parindent}{2em}
% \setstretch{1.25}
\doublespacing
\title{\singlespacing Regression analysis with linked data}
\author{Rachel Anderson\thanks{Mailing Address: Department of Economics, Julis Romo Rabinowitz Building,
Princeton, NJ 08544. Email: rachelsa@Princeton.edu.
This project received funding from the NIH (Grant 1 R01 HD077227-01). }}
\date{This Version: \today}

\begin{document}

\maketitle


\begin{abstract}
\singlespacing
\noindent This paper compares different methods for estimating parametric models with linked data, i.e. when $x$ and $y$ are observed in distinct datasets with imperfect identifiers.  This setup requires that the researcher must attempt to identify which observations in the $x$- and $y$-datafiles refer to the same individual, prior to performing inference about the joint or conditional distributions of $x$ and $y$.  At a minimum, random errors in the matching step introduce measurement error that must be accounted for in subsequent inference; however, additional concerns about sample selection arise when these errors are correlated with unobservables that affect $x$ or $y$.  \end{abstract}

% Using matched data requires estimation techniques that incorporate information from the matching process to improve efficiency and accurately reflect uncertainty. 

\section{Introduction}
My hypothesis: if you use deterministic matching, you should allow for multiple matches.  If you use probabilistic record linkage, you need to bias correct a la SW. 

Fix this

\section{Setup} 
Consider estimating $\beta$ in a linear regression model, \begin{equation} y_i = x_i'\beta + \varepsilon_i, \ E[\varepsilon | x_i] = 0, \ E[\epsilon_i^2] = \sigma^2  \label{model} \end{equation}
but, instead of observing $(x, y)$ pairs directly,  $x$ and $y$ are recorded in separate datasets.  Additionally, both datasets contain a set of common variables $w$, that can be used to link observations in order to learn about the joint distribution of $(x,y)$.

Perhaps the most straightforward way to estimate $\beta$ in this setting involves first identifying which $(x,y)$ pairs refer to the same underlying units, and then applying standard methods to estimate (\ref{model}) using the matched pairs.   Formally, for data $\{x_i, w_i\}_{i=1}^{N_x}$ and $\{y_j, w_j\}_{j=1}^{N_y}$, the matching step consists of estimating a function, \begin{equation} \varphi: \{1,\dots, N_x\} \to \{1,\dots, N_y\} \cup \varnothing \end{equation} where $\varphi(i) = j$ if individual $i$ in the $x$-datafile and individual $j$ in the $y$-datafile refer to the same entity, and $\varphi(i) = \varnothing$ if $i$ does not have a match in $y$-datafile.  Note that if $w$ identifies individuals uniquely and without error, then $\varphi(i) = j$ if and only if $w_i = w_j$, and $\varphi(i) = \varnothing$ otherwise.  However, if $w$ is not unique or recorded with error, then $\varphi$ needs to be estimated, and inference about $\beta$ may need to be adjusted accordingly.   

To fix ideas, consider the setup of \cite{aizer2016}, where the goal is to estimate the effect of providing cash transfers to single mothers on the life expectancy of their children.  Mathematically, the parameter of interest can be represented as $\beta_1$ in the regression model,
\begin{equation}
y_i = \beta_0 + x_{1i}  \beta_1+ x_{2i}'\beta_2 + \varepsilon_i
\end{equation}
where $x_{1i}$ is a binary variable equal to 1 if person $i$'s mother received a cash transfer, and $x_{2i}$ includes all other demographic variables that are recorded on the welfare program applications (the $x$-datafile).  The outcome $y_i$ is person $i$'s age at death, as reported in a universal database of death records (the $y$-datafile).  The two data sources additionally contain a common set of variables $w$, including first and last name, and year of birth.  Since no combination of these variables is necessarily unique, estimating $\varphi$ in this setting would likely require distinguishing among multiple observations with identical $w$.

Although the previous example is motivated by a specific research question in \cite{aizer2016}, the ``imperfect identifier problem" is by no means unique.  In statistics, the task of recovering $\varphi$ is known as \textit{record linkage}, but  this problem also appears frequently in computer science, operations research, and epidemiology, under names such as data linkage, entity resolution, instance identication, de-duplication, merge/purge processing, and reconciliation.  In economics, a strong interest in record linkage has emerged as the result of newly available, large administrative datasets; and, a number of recent papers compare the performance of popular matching techniques used in economic history on the representativeness and accuracy of the datasets that they produce \citep{abe2019,arp2018,bailey2017}.

% good until here
%Each step of the record linkage process introduces the possibility that a true match is overlooked (Type II error), or that a false match is designated as correct (Type I error); and, generally, there is a tradeoff between reducing either one of the two \citep{abe2019, harron2018}.  However, the impact of data pre-processing choices on estimation is still not well understood.  

The purpose of this paper is to show that inference using linked data requires making joint assumptions for the matching and estimation steps, such as whether multiple matches are allowed, and, if so, how these matches should be accounted for when using standard estimation techniques.  In the past, authors have handled multiple matches by generating a ``composite match" equal to the average of the linked observations \citep{bleakley2016}, constructing bounds on the parameter of interest using different configurations of matched data \citep{nq2015}, or using methods that allow for multiple outcomes by \cite{ahl2019} using weighted least squares.   Alternatively, if probabilistic record linkage methods are used, the bias introduced during the matching step may be removed using robust OLS estimators in \cite{lahiri05}, or prior-informed imputation in \cite{Goldstein2012}.   

This paper adds to this literature by comparing how different \textit{combinations} of matching and estimation techniques affect parameter estimates and their confidence intervals in standard econometric models.  It also makes practical suggestions for choosing which methods best suit a given setting. 


In order to illustrate the techniques studied in this paper, Section 2 introduces a numerical example that is used to demonstrate the matching and estimation techniques described in Sections 3 and 4.  Section 5 provides details about the implementation of the methods and data generating processes.  Section 6 contains the results, and Section 7 concludes.

\section{Numerical Example}

The purpose of this section is to introduce a synthetic dataset that will be referenced throughout this paper.  The benefits of using a synthetic dataset are threefold:  first, I can control which variables in (\ref{model}) are correlated with errors in the identifiers $w$; second, I can compare the performance of the matching algorithms and estimation techniques to a ``ground truth" dataset containing all of the true matches; third, I can control the degree of overlap and similarity among observations, which is imporrtant for manipulating the number of possible matches if multiple matches are desired.  To make the data as real as possible, I choose the identifiers and their corresponding transcription error rates to mimic those reported in the 1940 Census data, as reported by \cite{abe2019}. 

The ``ground truth" dataset consists of 1000 observations of $(x_{1i}, x_{2i}, y_i, w_i)$, where $x_{1i}$ and $x_{2i}$ are mutually independent, $x_{1i} \overset{i.i.d}{\sim} \text{Bernoulli}(0.5)$, and $x_{2i} \overset{i.i.d}{\sim} \mathcal{N}(0, 2)$.  The $y_i$ values are generated according to the linear relationship,
\begin{gather}
y_i = \beta_0 + \beta_1 x_{1i} + \beta_2 x_{2i} + \varepsilon_i, \hspace{10pt} 
\varepsilon_i\  |\  x_{1i}, x_{2i} \overset{i.i.d}{\sim} \mathcal{N}(0, \sigma^2) 
\end{gather}
with $(\beta_0, \beta_1, \beta_2, \sigma^2) = (2, 0.5, 1, 2)$, so that estimating the correctly specified linear regression model yields an $R^2$ value of approximately 0.50.  Each observation is also assigned the identifiers, $w_i$, which include include a first and last name drawn at random from a list of first and last names\footnote{The first and last name lists contain 41 and 24 names, respectively, and can be found in the replication files.  Note that the number of possible names is smaller than the number of observations to ensure that there are multiple observations with the same name.}, and a random birthday between January 1, 1900, and December 31, 1925.   The resulting dataset looks like the observations in the top panel of Figure \ref{sample_dta}.  
 
 % Massive latex Figure of synthetic dataset -- put in new file ideally
\begin{figure}[h!]
\caption{Creation of Synthetic Datasets}
\vspace{5pt}
 \begin{adjustwidth}{-.5in}{-.5in}  
\begin{tikzpicture}
\node (a) at (0,0){
\begin{tabular}{ccccccc}
\toprule
ID &  $y$ & $x_1$ & $x_2$ & First Name & Last Name & Birthday \\
\midrule
1 & $y_1$ & $x_{1,1}$ & $x_{2,1}$ & Tyler & Ashenfelter & 1915-05-13 \\
2 & $y_2$ & $x_{1,2}$ & $x_{2,2}$ & Brandon & Christensen & 1904-06-27 \\
\mc{7}{c}\vdots \\
195 & $y_{195} &$x_{1,195} & $x_{2,195}$ & Samantha & Andersen & 1914-08-18 \\
196 & $y_{196}$ & $x_{1,196}& $x_{2,196}$ & Victoria & Andersen & 1918-11-25\\
\mc{7}{c}\vdots \\ 
1000 & $y_{500}$ & $x_{1,500}$ & $x_{2,500}$ & Vicky & Anderson & 1915-04-14\\
\bottomrule
\end{tabular}};
\\
\vspace{20pt}
\\
\footnotesize{
\node[yshift=-3cm] (b) at (a.south){
\begin{tabular}{ cc }   % top level tables, with 2 rows
$x$-Datafile & $y$-Datafile \\  
% bottom left of the top level table: table 1 
\begin{tabular}{ cccc } 
\toprule
ID & $x$ & Name & Birthday \\
\midrule
2 & ($x_{1,2}, x_{2,2})$ & Branden Christenson & 1905-06-27 \\
\mc{4}{c}\dots \\
195 & ($x_{1,195},x_{2,195}$)& Samantha Anderson & 1914-08-21 \\
198 & ($x_{1,198}, x_{2,198}$)& Jon Smyth & 1918-12-20\\
\mc{4}{c}\dots \\ 
1000 & ($x_{1,1000},x_{2,1000}$) & Vic Andersn & 1915-04-14\\
\bottomrule
\end{tabular} &  % starting bottom right of the top level table
% table 2
\begin{tabular}{ cccc } 
\toprule
ID & $y$ & Name & Birthday \\
\midrule
1 & $y_1$ & Tyler Ashenfelter & 1915-05-13 \\
2 & $y_2$ & Brandon Christensen & 1904-06-27 \\
\mc{4}{c}\dots \\
195 & $y_{1,195}$ & Samantha Anderson & 1914-08-18 \\
\mc{4}{c}\dots \\ 
1000 & $y_{1000}$ & Vicky Anderson & 1915-04-14\\
\bottomrule
\end{tabular} \\
\end{tabular}};
\draw[->, thick](a)--(b);
\end{tikzpicture}
\end{adjustwidth}
\label{sample_dta}
\end{figure}%

Next, I split the ground truth dataset into an $x$- and $y$-datafile, which contain $(x_1,x_2, w)$ and $(y, w)$ values respectively.  To construct the $x$-datafile, I select 400 observations at random from the ground truth dataset, and introduce random errors in their corresponding identifiers.  These errors include deleting characters (e.g., ``Anderson"  becomes ``Andersn"), exchanging vowels (e.g., ``Rachel" becomes ``Rachal"), and swapping English phonetic equivalents (e.g. ``Ellie" becomes ``Elie").  I also add normally distributed errors to the birth day, month, and year.   The probabilities of introducing an error are set to match the transcription error rates reported in the 1940 Census by \cite{abe2019}; for example, 7\% of observations have misreported first names and 17\% of observations have misreported last names.  The bottom panel of Figure \ref{sample_dta} illustrates how the $x$- and $y$-datafiles are split visually.  

The $y$-datafile includes all 1,000 values from the ground truth data, and does not contain any errors in the identifiers $w$.  As a result, it will be likely that  some $x$ will be matched to multiple $y$.  In later sections, I will consider versions of this synthetic dataset, where errors in $w$ are correlated with $x_{1}$ or $y$. 


\section{Record Linkage Methods}

Recall that the data consist of an $x$-datafile, denoted $X \equiv \{(x_i, w_i): i  = 1,\dots,N_x \}$, and a $y$-datafile, denoted $Y \equiv \{(y_j,w_j): j = 1, \dots, N_y\}$, and the goal of record linkage is to use $w_i$ and $w_j$ to determine which $i \in \{1, \dots, N_x\}$ and $j \in \{1, \dots, N_y\}$ refer to the same individual.  

For the purposes of this paper, I define a record linkage procedure as a set of decisions about (i) selecting and standardizing the identifying variables in $w_i$ and $w_j$, (ii) choosing which $(i,j)$ pairs to consider as potential matches, (iii) defining which patterns of $(w_i,w_j)$ constitute (partial) agreements, and (iv) designating $(i,j)$ pairs as matches.\footnote{By contrast, \cite{bailey2017} categorize record linkage procedures according to the set of assumptions that motivate their use.}  

Step (i) addresses the fact that differences may arise in $w_i$ and $w_j$ because of transcription error or misreporting, even when observations $i$ and $j$ refer to the same individual.   In practice, this step consists of removing spaces and non-alphabetic characters from string variables and processing names with phonetic algorithms to account for potential misspellings; common nicknames may also be replaced with full names.  

Step (ii) reduces the computational burden of a matching procedure when $N_x \times N_y$ is large by partitioning $X\times Y$ into ``blocks."  Only records within the same block are attempted to be matched, while records in different blocks are assumed to be non-matches.  Blocking variables should be recorded with minimal error, otherwise blocking may adversely affect the Type II error rate. 

Step (iii) defines a metric for quantifying the similarity between non-numeric variables, such as Jaro-Winkler distances for strings.  For more details, see \cite{arp2018}. 

Finally, Step (iv) is where record linkage procedures differ in the most meaningful ways; hence, this step will be the focus of my analysis.  Consider the following (deterministic) record linkage procedure as an example:
\begin{enumerate}
\item[(i)] Use a phonetic algorithm to standardize the first and last names in both datasets; 
\item[(ii)] Consider as potential matches all $(i, j)$ pairs whose phonetically standardized names begin with the same letter, and whose birth years are within $\pm$2 years;
\item[(iii)] Measure the distance between any two names using Jaro-Winkler string distance, and the distance between any two birth dates as a difference in months;
\item[(iv)] Designate as matches all $(i,j)$ pairs with Jaro-Winkler scores exceeding a pre-determined cut-off; and, if a record $i$ has multiple possible matches that exceed the cut-off, then choose the corresponding $j$ with the highest score (or pick one match at random if there is a tie).  
\end{enumerate}
Another record linkage procedure could be defined using the same steps (i)-(iii), but replacing (iv) with a probabilistic matching rule that does not enforce one-to-one matching:
\begin{enumerate}
\item[(iv*)]  Use the Expectation-Maximization algorithm to compute ``match weights" for each $(i,j)$ pair; then, designate as matches all pairs with match weights exceeding a threshold that is set to reflect specific tolerances for Type I and Type II error. 
\end{enumerate} 

Except in rare cases, the estimated matching functions obtained by switching (iv) and (iv$^*$) will differ, if only because the former method matches each $x$ with at most one $y$, the latter potentially matches the same $x$ with multiple $y$.  This example also illustrates the difference between deterministic and probabilistic record linkage methods: while (iv) uses pre-determined rules to designate pairs as matches, (iv*) uses statistical theory to inform the selection of the decision rule.  Probabilistic record linkage also involves the estimation of match weights, which can be incorporated in subsequent estimation steps.

Below I will discuss two record linkage methods -- one deterministic and one probabilistic -- that I will use in my analysis.  Each method will be implemented twice: first, requiring unique matches, and then allowing for multiple matches.  While these methods are by no means exhaustive, they are intended to be representative of the most commonly used methods in economics.  For a detailed survey of record linkage techniques, please refer to books by \cite{harron_book, christen2012} or \cite{herzog07}, or any of the references in this paper. 

\subsection{Deterministic}
The deterministic matching algorithm described herein is based upon methods developed by \cite{abe2012}.  It consists of the following steps.
\begin{enumerate}
\item Clean names in the $x$- and $y$- datafiles to remove any non-alphabetic characters and account for common mis-spellings and nicknames (e.g., so that Ben and Benjamin would be considered the same name).  
\item Restrict the sample to people in the $x$-datafile with unique first name, last name, and birth year combinations  
\item For each record in the $x$-datafile, look for records in the $y$-datafile that match on first name, last name, place of birth, and exact birth year.  At this point there are three possibilities 
\begin{enumerate}
\item If there is a \textit{unique} match, this pair of observations is considered a match.
\item If there are multiple potential matches in the $y$-datafile with the same year of birth, the observation is discarded. 
\item If there are no matches by exact year of birth, the algorithm searches for matches within $\pm$ 1 year of reported birth year, and if this is unsuccessful, it looks for matches within $\pm$ 2 years.  In each of these steps, only unique matches are accepted.  If none of these attempts produces a unique match, the observation is discarded.
\end{enumerate}
\item Repeat Step 3 for each record in the $y$-datafile, searching for matches in the $x$-datafile; then designate as matches all record pairs in the intersection of the two matched samples.
\end{enumerate}

An interesting quirk of this algorithm is that an individual with multiple matches is dropped from the sample only if those matches occur before a unique match is found in Step 3.  That is, a person with a unique, same-year match, and multiple matches with birth years within one year, will not be dropped from the sample.  If the same-year match were not included in the dataset, then that same individual would be dropped.  This has significant implications for bootstrapping standard errors; notably, the nonparametric bootstrap will fail. 

Note that this quirk only occurs when the algorithm enforces unique matches.  When allowing for multiple matches, I designate as a match any pair that satisfies any of the categories in Step 3. 

\subsection{Probabilistic Record Linkage}
The probabilistic record linkage technique implemented in this paper is based on the canonical model by \cite{fellegi69}, which views record linkage as a classification problem, where every record pair belongs either to the set of \textit{matches} $(M)$ or \textit{non-matches} $(U)$:
\begin{align*} M &= \{ (i,j) \in X\times Y: j \in \varphi(i) \} \\ U &= \{(i,j) \in X\times Y:  j \notin\varphi(i)\}\end{align*} 

 To determine whether a record pair $(i,j)$ belongs to $M$ or $U$, the pair is evaluated according to $K$ different comparison criteria.  These comparisons are represented in a \textit{comparison vector}, $$\mathbf{\gamma_{ij}}= (\gamma_{ij}^1, \dots, \gamma_{ij}^{k}, \dots, \gamma_{ij}^K)$$  where each comparison field $\gamma_{ij}^{k}$ may be binary-valued, as in ``$i$ and $j$ have the same birthday" and ``$i$ and $j$ have the same last name," or use ordinal values to indicate partial agreement between strings.

The probability of observing a particular configuration of $\gamij$ can be modeled as arising from the mixture distribution:
\begin{equation}
P(\gamij) = P(\gamij | M) p_M + P(\gamij | U) p_U 
\label{mm}
\end{equation}
where $P(\gamij | M)$ and $P(\gamij | U)$ are the probabilities of observing the pattern $\gamij$ conditional on the record pair $(i,j)$ belonging to $M$ or $U$, respectively.  The proportions $p_M$ and $p_U = 1-p_M$ are the marginal probabilities of observing a matched or unmatched pair.  Applying Bayes' Rule, we obtain the probability of $(i,j) \in M$ conditional on observing $\gamij$,
\begin{equation} P(M | \gamij) = \frac{p_M P(\gamij | M)}{P(\gamij)} \label{bayes} \end{equation}
Thus, if we can estimate $p_M$, $P(\gamij | M)$ and $P(\gamij | U)$, then we can estimate the probability that any two records refer to the same entity using (\ref{bayes}).   These probabilities can then be used to designate pairs as matches, or to estimate the false positive rate associated with a particular match configuration using the formulas in \cite{fellegi69}.  

One difficulty arises from the fact that there are at least $2^K -1$ possible configurations of $\gamij$\footnote{There are more, if any of the comparison criteria are non-binary}.  While in principle we could model $P(\gamij | M)$ and $P(\gamij | U)$ as
\begin{align*} (\gamma_{ij}^1, \dots, \gamma_{ij}^K) \  |\  M &\sim \text{Dirichlet}(\mathbf{\delta_M})\\
 (\gamma_{ij}^1, \dots, \gamma_{ij}^K) \  |\  U &\sim \text{Dirichlet}(\mathbf{\delta_U}) \end{align*}
but the parameters $\mathbf{\delta_M}$ and $\mathbf{\delta_U}$ may be high-dimensional.  However, if the comparison fields $\gamma_{ij}^{k}$ are independent across $k$ conditional on match status, then the number of parameters used to describe each mixture class can be reduced to $K$ by factoring:
 \begin{equation} 
 P(\gamma_{ij} | C) = \prod_{k=1}^K P(\gamma_{ij}^{k} | C)^{\gamma_{ij}^{k}}(1-Pr(\gamma_{ij}^{k} | C))^{1-\gamma_{ij}^{k}} \hspace{20pt} C\in \{M, U\} 
 \label{eq:condInd}
 \end{equation}
 Alternatively, dependence between fields can be modeled using log-linear models; however, I will assume conditional independence to ease computation, and because the matching variables in the synthetic dataset are generated independently of each other.  
 
Since membership to $M$ or $U$ is not actually observed, a convenient way of simultaneously estimating $p_M, p_U$ and classifying record pairs as matches or non-matches is via mixture modeling, with mixture distributions $P(\gamij | M)$ and $P(\gamij | U)$.  The parameters can be estimated using the expectation-maximization (EM), first applied to record linakge by \cite{larsen_rubin_2001}.  For this paper, I use the \texttt{fastLink} algorithm developed by \cite{enamorado2019}. 

\section{Estimation with linked data }

When performing estimation with linked data, a few obvious comparison metrics arise:  data can be partitioned into three parts - identfied links, nonlinks and potential links.  Could repeat the analysis for each group or for subsets of these groups.  They use nonlinks to adjust the potential links, and thereby, gain an additional perspective that could lead to reductions in MSE over statistics calculated only from the linked data.  Benchmark is OLS with one-to-one-matching, or using observations assigned $L_i = 1$ matches. 

Using only data from pairs of records that are highly likely to be links might mean throwing away additional information from potentiallyl inked pairs, which could contain true links.  Additionally, we could bias results because confidently linked pairs may differ from potentially linked piars.  For example, considering affirmative actiona nd income questison, certain records may be harder to match.  For deterministic methods, people reweight on observables.. 

Some methods specifically attempt to correct for the bias introduced by the matching step.  Seminal work by Neter, Maynes and Ramanathan (1965) shows that if matching errors are moderate then regression coefficeints can be severely biased.  This work is formalized by \cite{sw1993}. 

The primary examples are \cite{lahiri05} and \cite{sw1993}.  \cite{sw1993} presuppose that the linker has provided a combined data file consisting of pairs of records (one from each input file) along with the match probability and the link status -- either link, nonlink, or potential link -- of each pair.  They assume that the file of linked cases has been augmented so that every record on the smaller of the two files has been paired with two records of the larger file having the highest matching weights.  Some cases will consist of (link, nonlink) combinations or (nonlink, nonlink) combinations, but they rule out settings where more than one true link could occur, so that (link link) combinations are ruled out.

Formally \cite{sw1993} assume that the matching procedure produces $n$ pairs $(x_i, z_i)$, where $z_i$ may or may not correspond to $y_i$, yet the true $y_i$ is included among the potential matches.   Hence, 
$$z_i = \begin{cases} y_i & \text{with probability $q_{ii}$} \\ y_j & \text{with probability $q_{ij}$ for $j\neq i,\ j = 1,\dots,n $} \end{cases}$$ 
and $\sum_{j=1}^n q_{ij} = 1, \ i=1,\dots, n$.  Estimating (\ref{model}) using $z_i$ as the dependent variable yields the naive least squares estimator, 
\begin{equation} \hat{\beta}_N = (X'X)^{-1} X'z \label{naive} \end{equation}
which is biased.   Denoting $q_i = (q_{i1}, \dots, q_{in})'$ and $Q = (q_1, \dots, q_n)'$, we can write the bias of $\hat{\beta}_N $ as
$$\text{bias}(\hat{\beta}_N) = [(X'X)^{-1} X'QX - I] \beta $$ 
 since $E[z_i] = E[q_i'y]  = q_i'X\beta =  \sum_{j=1}^{n} q_{ij} x_j'\beta $.  

To reduce the bias of $\hat{\beta}_N$, \cite{sw1993} observed that 
\begin{equation} \text{bias} (\hat{\beta}_N | y) = E[(\hat{\beta}_N - \beta) | y ] = (X'X)^{-1} X'B \label{bias} \end{equation}
where $B = (B_1, \dots, B_n)'$ and $B_i = (q_{ii}-1)y_i + \sum_{j\neq i } q_{ij} y_j = q_i'y - y_i$, which is the difference between a weighted average of responses from all observations and the actual response $y_i$.  The authors suggest estimating (\ref{bias}) using the first and second highest elements of the vector $q_i$, so that $\hat{B}_i^{TR} = (q_{ij_1} - 1) z_{j_1} + q_{ij_2} z_{j_2}$, and 
\begin{equation} \hat{\beta}_{SW} = \hat{\beta}_N - (X'X)^{-1} X' \hat{B}^{TR} \label{sw}\end{equation}
The estimator can incorporate any number of elements of $q_i$, but, if the probability is high that the best candidate link is the true link, then the truncation  results in a very small bias. 

Alternatively,  \cite{lahiri05} use the fact that $E(z_i) = w_i'\beta$, where $w_i = q_i'X_i\beta$, to construct the unbiased estimator:
$$ \hat{\beta}_U = (W'W)^{-1} W'z$$ 
where $W = (w_1, \dots, w_N)'$.  To construct $\hat{\beta}_U$ in practice, they also recommend using a truncated version of $W$, with $w_i^{TR} = q_{ij_1} x_{j_1} + q_{ij_2} x_{j_2}$.

For both methods, the values $q_{ij}$ are typically calculated using (\ref{bayes}) and parameter values $\psi = \{p_M, P(\gamij | M)$, and $P(\gamij |U)\}$. Thus, we can write the estimators $\hat{\beta}_{SW} = \hat{\beta}_{SW}(\psi)$ and $\hat{\beta}_U = \hat{\beta_U}(\psi)$.  In practice, $\psi$ is unknown, and a reasonable estimator $\hat{\psi}$ must be used.   Details on how to estimate $\hat{\psi}$ are provided in the next section.   Importantly, $\hat{\beta}_U(\hat{\psi})$ is unbiased whenever $\hat{\psi}$ is independent of $z$, which occurs if errors in the matching variables (which determine the distribution of $\hat{\psi}$ are independent of the response variable $y$.  Unfortunately, this assumption is unlikely to hold in many economic applications, such as \cite{nq2015}, where $y$ indicates whether a person's recorded ethnicity changes between survey years, but data quality significantly differs for individuals with different values of $y$.  

The work of \cite{ahl2019} is like a generalized version of \cite{sw1993}.  They propose a GMM estimator that uses data where each observation $x_i$ is linked to $L_i$ equally likely, potential outcomes, denoted $\{y_{i\ell}\}_{\ell=1}^{L_i}$.  Importantly, their methods require that (i) the true outcome is included among the set of possible matches, (ii) each of the possible matches is equally likely to be the true match, and (iii) that the observations $x_i$ and $\{y_{i\ell}\}_{\ell=1}^{L_i}$ are random samples from their marginal distributions conditional on $(w_i, L_i)$.  
 
Under these assumptions, the authors show how to construct an unbiased and consistent estimator $\hat{\beta}$ by considering the smoothed regression:
\begin{equation} 
\sum_{\ell=1}^{L_i} y_{i\ell} - (L_i - 1)g(w_i, L_i) = x_i'\beta + u_i  \end{equation}

\noindent where $g(w_i, L_i) = E[y_{i\ell} | w_i, L_i ]$, $u_i = \varepsilon_i + \sum_{\ell=1}^{L_i}\nu_{i\ell}$, and $\nu_{i\ell} = y_{i\ell} - E[y_{i\ell} | w_i, L_i ]$. 

If, additionally, $E[\varepsilon_i^2 | w_i, L_i] = \sigma_{\varepsilon}^2$ and $E[\nu_{i\ell} | z_i, L_i] = \sigma_{\nu}^2$ then $\hat{\beta}$ can be estimated efficiently using weighted least squares, with $\sigma(X_i) = \sigma_{\varepsilon}^2 + (L_i - 1)\sigma_{\nu}^2$, and
\begin{equation}
\hat{\beta}^{WLS} = \left(\sum_{i=1}^N \frac{x_ix_i'}{\sigma(X_i)}\right)^{-1}\left(\sum_{i=1}^N \frac{x_i}{\sigma(X_i)}\left(\sum_{\ell=1}^{L_i} y_{i\ell} - (L_i - 1) g(w_i, L_i)\right)\right)
\end{equation}
which can be estimated in two-steps, where the first step involves estimating $\hat{g}(\cdot)$ and $\hat{\sigma}(X_i)$.  The resulting estimator is consistent and asymptotically normal under the regularity conditions described in \cite{ahl2019}. 

Assumption (iii) rules out the possibility of unobserved sample selection, in the sense that all individuals with the same identifying information have equal probability of appearing in the sample.  This assumption would be violated if, for example, higher income individuals have a greater probability of appearing in the sample (unless $w_i$ includes income).   However, unlike the OLS bias correction estimators, the methods here explicitly correct for any dependence between the outcome variable and the matching variables $w_i$ and the parameters of the matching procedure, insofar as they are captured by $L_i$.  

[This suggests that the AHL (2019) estimator may be more robust when $L_i$ is correlated with $x_i$..]

\section{Estimation with linked data and probabilities} 

Here we consider the possibility of incorporating probabilities of matches in the AHL framework.  The interesting result is that the minimum variance unbiased estimator depends on the ratio of the structural error in the model to the variance in the reduced form estimation for $y$, which also depends on the precision of the estimator $\hat{g}$.  This is an interesting result because it connects to the Horwitz-Thompson estimator, and work on inverse propensity score weighting. 

\section{Monte Carlo Study}

Following the same procedure for simulating the empirical example described in Section 2, I generate 1,000 random $x$- and $y$- dataset pairs.  I implement four types of matching procedures using each dataset pair: (i) deterministic matching with unique matches (ABE Single), (ii) deterministic matching with multiple matches (ABE Multi), (iii) probabilistic matching with unique matches (PRL Single), and (iv) probabilistic matching with multiple matches (PRL Multi).  Allowing for multiple matches means that a single observation in the $x$- datafile may be matched to multiple observations in the $y$-datafile.  

Each matching method produces a distinct matched dataset, so that the matching step produces a total of 4,000 linked datasets.  For each of these datasets, I then compute a variety of estimates of $\beta$, primarily the Scheuren-Winkler bias-correction estimator,  and the AHL estimator that allows for multiple matches.  I additionally compute three standard OLS estimators; the first using only observations that are assigned a single match by the record linking procedure, and the second using only the correctly matched pairs.  The third OLS estimator is the benchmark estimator is $\hat{\beta}^{opt}$, which is calculated using the correctly linked version of the $x$- and $y$-dataset pair.  Details on the implementation of these algorithms and estimation procedures can be found in the appendix.  

\subsection{Matching results}
To evaluate the matching procedures, I compute the following statistics for each linked dataset, reported in Table \ref{match_rate}:

\begin{itemize}
\item the proportion of observations in the $x$-datafile that are linked to at least one observation in the $y$-datafile (match rate), 
\item the total number of links made by the matching algorithm, 
\item the proportion of links that are incorrect (Type I error rate), 
\item the proportion of correct $(x,y)$ links that are not found by the matching algorithm (Type II error rate), 
\item the proportion of observations whose links include the true match
\end{itemize}

\noindent For the linked datasets that contain multiple matches per observation, I report also the average number of links per observation, and how often those links include the true match (Table \ref{multi_L}). 

%% Matching Algorithm Comparison
% Match Rate Table 


\begin{table}[h!]
\let\center\empty
\let\endcenter\relax
\centering
\caption{Average performance and SD for matching algorithms}
\vspace{10pt}
\resizebox{\textwidth}{!}{\input{./Figures/match_rates.tex}}
\label{match_rate}
\end{table}

\begin{table}[h!]
\let\center\empty
\let\endcenter\relax
\centering
\caption{Average performance and SD for multiple match procedures}
\vspace{10pt}
\resizebox{1.1\textwidth}{!}{\input{./Figures/multi_tab.tex}}
\label{multi_L}
\end{table}

%  Match Rate Histograms 
\begin{figure}[htbp]
\begin{center}
\caption{Match Rates by Linking Procedure } 
\includegraphics[width=0.9\textwidth]{./Figures/match_rate.pdf}
\label{match_hist}
\end{center}
\end{figure}


Here are some observations that need to be turned into paragraphs: 
\begin{itemize}
\item As seen in Table \ref{match_rate}, the average match rates range between 71 and 79 percent across the various matching procedures.  I also plot the distribution of match rates across replications in Figure \ref{match_hist}.   The distribution for ABE Multi lies almost entirely to the right of the mean match rate for the other procedures.  The PRL Single and PRL Multi have about the same match rate, which suggests that allowing for multiple matches does not match new individuals, but instead adds additional noise.  ABE Multi, on the other hand, increases match rates by matching new observations.  
\item ABE Multi appears to be the least discriminating of the matching procedures, with higher match rates across all replications, and with the highest number of matches.
\item PRL Single matches more observations than ABE Single, but those extra matches seem more often to be wrong (check with a regression?) because the Type I error rate is higher. 
\item The multi-match methods have higher Type I error rates by construction; despite adding false matches, they seem to improve upon the unique-match methods because they are more likely to include the true match among the possible matches. 
\item  ABE Single is the most conservative of all the matching algorithms, with the lowest match rate and lowest type I error.  Of course, the tradeoff is that it fails to identify a quarter of all possible matches. 
\item  It seems like PRL Single is the worst performing algorithm -- despite higher match rates than ABE single it seems that those matches are not likely to be correct.  This may be an artifact of the threshold used to assign the matches.  A higher threshold may result in matches more similar to ABE Single.  It may be interesting to calculate whether these two algorithms are systematically matching different types of record pairs. 
\item In Table \ref{multi_L}, we see that PRL Multi is more likely to match observations to a unique outcome; at the price of sometimes excluding the true match.  ABE Multi is more likely to assign more matches, however the true match is contained with high probability.   Few observations are matched with more than three different outcomes.  %% FIX THIS BECAUSE THE PR(L=l) does not add up to one!!!
\item Based on these results, I hypothesize that ABE Multi seems to be the best performing match procedure, if multiple matches are desired.  This is because the methods described in this paper typically require that the true match be included among the matches.  But another question is how much noise do extra matches introduce.  
\item I compare also ABE Multi and PRL Multi to determine whether the probability of containing a true match increases by allowing for multiple matches (Table \ref{multi_tab}).   In both procedures, more than half of observations are matched to a unique outcome, and those outcomes are correct 99 and 97 percent of the time for ABE Multi and PRL Multi, respectively.   Essentially, allowing for multiple matches in the deterministic procedure increases the probability that the true match is contained among the possible matches.  
\end{itemize}

\subsection{Estimation Results}

Benchmark is ... 

AHL Estimator performs well.... 

OLS with (L=1)

When only a single matching is allowed, it is not possible to use SW method because it requires that we carry over multiple matches for each observation.   

\begin{table}[h!]
\let\center\empty
\let\endcenter\relax
\centering
\caption{Median Absolute Deviations for Estimators}
\vspace{10pt}
\resizebox{0.9\textwidth}{!}{\input{./Figures/est_tab.tex}}
\label{multi_tab}
\end{table}

\begin{figure}[htbp]
\begin{center}
\caption{Comparing OLS with true matches produced by matching algorithm vs. matches with L=1}
\includegraphics[width=1.1\textwidth]{./Figures/compare.pdf}
\label{default}
\end{center}
\end{figure}


\section{Discussion}
To what extent my results generalize beyond the simulated data is unclear.  Many arbitrary choices -- name dictionary choice, uniform probability over those names -- and how I introduced error in the identifying variables may impact my results in important ways.  This needs to be studied in more detail, ideally with real data where a ground truth is also available. 

%  Multi Match Table 




I evaluate the performance of the matching procedures and estimation procedures using the following criteria.  For the matching procedures, I calculate

I compare estimators according to median absolute deviation.  I plot a histogram of the estimators. 


\section{Implementation Notes}
Here I will talk about all the nit-picky stuff, like 
\begin{itemize}
\item what threshold level I use for the fastLink algorithm (0.6)
\item what nonparametric technique I use for AHL (nearest neighbor) 
\item how I choose z in LL when there are multiple matches (randomly)
\item how I calculate standard errors for all of the estimators (using formulas for now)
\item how I standardize the variables for matching (nysiis function in R)
\item I change Step 2 in the ABE algorithm to restrict the all observations with unique first name, last name, date of birth, and $(x_1, x_2)$ combinations. 
\item  When allowing for multiple matches, I count as matches all record pairs with the same name, and the difference in recorded birth years is within two (or five) years.  That is, I designate all potential matches that arise in Step 3 as matches. 
\end{itemize}

\section{Results}
In total, I will test three DGPs (two now; more in Monte Carlo). The first is exactly as described in Section 2.  The second allows for correlation  between $x_1$ and the probability of an error.  The third will allow for correlation between $y$ and the probability of an error. 

The $y$ are generated according to the same DGP described above; that is the true $\beta_0 = (2, 0.5, 1)$.  I compare my results to an oracle linkage method (``first best"), which would successfully link all 400 $x$ observations to their correct $y$.  

I haven't finished coding, but here is an overview of the figures and tables so far:
\begin{itemize}
\item Table \ref{match_rate} shows the number of matches, percent correct, and number of uniquely matched $x_i$ for each matching method.  We see that no method is able to match every observation in the $x$ datafile.  The ABE method performs the best, but I also use a small threshold for PRL that could potentially be adjusted in order to achieve similar performance. 
\item Table \ref{naive} shows the OLS results applied naively (without any corrections for double counting $x$ with multiple $y$) to each of the matched datasets.  The First Best estimator is the benchmark case, produced by perfectly matched data. 
\item Another way to view the output of the matching algorithms is Figure \ref{match_plot} (but this is kind of messy and maybe a QQ plot is better?)
\item Figure \ref{nMatches} shows the distribution of $L_i$ for methods that create multiple matches.  
\item Table \ref{estimates} contains parameter estimates and standard errors (not always correcT) for different estimation methods on different datasets that can be compared to the naive OLS.
\end{itemize}% results here


% Naive OLS Table
\begin{table}[h!]
\let\center\empty
\let\endcenter\relax
\centering
\caption{Naive OLS for all of the matchings}
\resizebox{\textwidth}{!}{\input{./Figures/naive_ols.tex}}
\label{naive}
\end{table}

% match plot
\begin{figure}[htbp]
\label{match_plot}
\caption{$(x,y)$ pairs produced by different matching algorithms}
\begin{center}
\includegraphics[width=\textwidth]{./Figures/match_plots.pdf}
\label{default}
\end{center}
\end{figure}

\begin{table}[htdp]
\label{estimates}
\let\center\empty
\let\endcenter\relax
\centering
\caption{Parameter estimates for different matched datasets and estimation procedures}
\vspace{10pt}
 \addtolength{\leftskip} {-1.5cm} 
 \addtolength{\rightskip}{-1cm}
\resizebox{1.2\textwidth}{!}{\input{./Figures/estimates.tex}}
\end{table}

\newpage
% distribution of estimators
\begin{figure}[htbp]
\label{ahl_hist}
\begin{center}
\includegraphics[width=\textwidth]{./Figures/ahl_hist.pdf}
\label{default}
\end{center}
\end{figure}

\begin{figure}[htbp]
\label{sw_hist}
\begin{center}
\includegraphics[width=\textwidth]{./Figures/sw_hist.pdf}
\label{default}
\end{center}
\end{figure}


\begin{figure}[htbp]
\label{ols_hist}
\begin{center}
\includegraphics[width=\textwidth]{./Figures/OLS(L=1)_hist.pdf}
\label{default}
\end{center}
\end{figure}





\section{Conclusion}
Will write when I have results. 





\newpage
\singlespacing
\bibliography{./Deadlines/proposal_bib} 
\bibliographystyle{aer}

\end{document}