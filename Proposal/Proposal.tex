\documentclass[12pt]{article}
\usepackage[margin=0.1in]{geometry}
\usepackage{xcolor}
\usepackage{framed}
\usepackage{enumitem}
\usepackage{natbib}
\usepackage{mathtools,xparse}
\usepackage{graphics}
\colorlet{shadecolor}{orange!15}
% \definecolor{shadecolor}{rgb}{255,128,0}\
\usepackage{float}
\usepackage{fullpage} % Package to use full page
\usepackage{parskip} % Package to tweak paragraph skipping
\usepackage{tikz} % Package for drawing
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{hyperref}
\usepackage{setspace}
\usepackage{graphicx} % Allows including images
\usepackage{booktabs} % Allows the use of \toprule, \midrule and \bottomrule in tables
\usepackage{longtable}
\usepackage{indentfirst}
\usepackage{tikz}
\usetikzlibrary{arrows,shapes,positioning,shadows,trees}

\tikzset{
  basic/.style  = {draw, text width=2cm, drop shadow, font=\sffamily, rectangle},
  root/.style   = {basic, rounded corners=2pt, thin, align=center,
                   fill=green!30},
  level 2/.style = {basic, rounded corners=6pt, thin,align=center, fill=green!60,
                   text width=8em},
  level 3/.style = {basic, thin, align=left, fill=pink!60, text width=6.5em}
}

%Allows multi-column tables 
\input{../tcilatex}

\setlength{\topmargin}{-0.4in} 
\setlength{\textheight}{8.9in}
\setlength{\parindent}{2em}
% \setstretch{1.25}
\doublespacing
\title{\singlespacing The effects of matching algorithms and estimation methods using linked data}
\author{Rachel Anderson\thanks{Mailing Address: Department of Economics, Julis Romo Rabinowitz Building,
Princeton, NJ 08544. Email: rachelsa@Princeton.edu.
This project received funding from the NIH (Grant 1 R01 HD077227-01). }}
\date{This Version: \today}

\begin{document}

\maketitle


\begin{abstract}
\singlespacing
\noindent This paper studies the effect of different matching algorithms and estimation procedures for linked data on the quality of the estimates that they produce.  \end{abstract}

\section{Introduction}
In applied microeconomics, identifying a common set of individuals appearing in two or more datasets is often complicated by the absence of unique identifying variables. For example,  \cite{aizer2016} link children listed on their mother's welfare program applications with their death records using individuals' names and dates of birth.  However, since name and date combinations are not necessarily unique (and may be prone to typographical error), the authors identify cases where multiple death records seem to refer to the same individual.  Instead of dropping these observations from their analysis, they use estimation techniques from \cite{ahl2019} that allow for observations to have multiple linked outcomes.  

The methods in \cite{ahl2019} assume that each of the linked outcomes is equally likely to be the true match; however, the authors describe how to construct more efficient estimators if additional information about match quality is available.  Specifically, if the researcher can estimate the probability that each individual-outcome pair is a true match, then this knowledge can be used to achieve a reduction in mean-squared error.  Such probabilities are outputted by probabilistic record linkage procedures, first developed by \cite{fellegi69} in the statistics literature, but only recently applied to economics \cite{arp2018}. Hence, any discussion of best practices for using linked data should address how to choose matching algorithms and estimation procedures jointly.  

The goal of this paper is therefore to study the effects of different combinations of matching algorithms and estimation procedures for linked data on the quality of the estimates that they produce.  First, I will compare how different matching algorithms perform in terms of the representativeness of the matched data they produce and their tolerance for type I and type II errors.  Next, with multiple matched versions of the data in hand, I will compute point estimates and confidence intervals for the same parameter of interest using methods that vary by whether they allow for multiple matches, incorporate the matching probabilities, and are likelihood-based in their approach.  In total, I will perform the above analysis twice -- with simulated data and with real data that the simulated data are generated to imitate.  

To the best of my knowledge, how data pre-processing impacts subsequent inference in economics research is not well understood.  This paper adds to a recent series of papers by \cite{arp2018} and \cite{abe2019}, who seek to understand how different matching algorithms impact the quality of inference.  This paper goes a step further, by testing also the effect of different estimation techniques that incorporate information from the matching process, and uses simulations to make more generalizable conclusions.  

Matching techniques will include deterministic record linkage as described in \cite{ferrie}, and \cite{arp2018}, and multiple implementations of probabilistic record linkage, specifically the fastLink \cite{enamorado2019}, and machine learning approaches \cite{Feigenbaum2016AML}. Estimation techniques will include \cite{ahl2019}, \cite{lahiri05}, and a fully Bayesian approach that I will develop in this paper. 

The real data consists of the unmerged files from \cite{aizer2016}, which I will pre-process using the practices developed by \cite{arp2018}.  The parameter of interest is the average treatment effect of a conditional cash transfer program on recipients' children's longevity.   

By Friday, I will write a description of the model, the parameter of interest, and the set of assumptions that I will use.   I will also provide a list of the matching and estimation techniques (with descriptions) that I will study, as well as a timeline for implementing each of them. 
\bibliography{./proposal_bib} 
\bibliographystyle{IEEEtranN}
\newpage
\section{Matching Methods}

A matching procedure is a set of choices about (i) selecting which variables to use when matching, (ii) defining a ``distance" metric between said variables, (iii) blocking observations into non-overlapping groups for computational feasibility, and (iv) designating record pairs as matches if a one-to-one matching is desired.    

Matching procedures can be divided into two categories, (i) deterministic approaches, where a fixed set of rules determine which records are matching and which are not; and (ii) probabilistic methods, which involve estimating the probability that each record pair refers to a match.  COMPARE AND CONTRAST WEAKNESSES.  Deterministic approaches are susceptible to X YZ  see Enamorado, etc. 

\begin{figure}[h!]
\centering
\caption{Overview of matching methods}
\includegraphics[width=0.7\textwidth]{./RecordLinkageGraphics.pdf}
\end{figure}

INSERT A GRAPHIC WITH THE METHODS I WILL TEST
\begin{itemize}
\item Deterministic
\item Probabilistic  (see Winkler 2006 for survey)
\begin{itemize}
\item E-M Algorithm
\item Training sample (Ruggles and Feigenbaum)
\item IPUMS linking method:  trains support vector machine on training sample of manually classified records (like Feigenbaum 2016)  In historical applications this is problematic due to sample attrition.  The DGP changes, so a full likelihood is a good idea. 
\end{itemize}
\end{itemize}
- Overview of matching methods

Important measurements:  estimated type 1, type 2 errors; representativeness of sample, sample size, overlapping of samples 
- Comparison of matching methods from (a) theoretical perspective, (b) with simulated data, (c) with actual data
\begin{enumerate}
\item  Estimation Methods 
\begin{itemize}
\item Anderson, Honore, Lleras-Muney (2019)
\item Lahiri Larsen
\item Scheuren Winkler 
\end{itemize}
- Overview of estimation methods


- Comparison of estimation methods from (a) theoretical perspective, (b) with simulated data, (c) with actual data

(3) Further investigation/follow-up simulations inspired by steps 1 and 2  
\end{enumerate}



% In contrast to deterministic record linkage, which has been used extensively in the economics literature (Ferrie, cite etc.).... descriptions here

% Thus, it is the goal of this paper.  



% In the literature, there are different methods for matching:  deterministic matching methods, such as those used by Joe Ferrie, probabilistic record linkage, and machine learning techniques.   Using the same datasets (simulated and real), I will apply each of these methods in order to create different matched versions of the same datasets. 

% The output of the matching algorithms are different.  In the case of deterministic matching, the output is a configuration of the data.  However, probabilistic and machine learning matching also output estimated probabilities of matches, which are then available for subsequent inference.   One question that AHL examine is how using information about match quality can improve the quality of the estimators, in terms of MSE reduction.   


I will also allow for missing data. 

\section{Annotated bibliography}
\begin{itemize}
\item Neter, Maynes, and Ramanathan (1965): small mismatch errors in finite population sampling can lead to a substantial bias in estimating the relationship between response errors and true values
\item Scheuren and Winkler (1993): propose method for adjusting for bias of mismatch error in OLS
\item SW (1997, 1991): iterative procedure that modifies regression and matching results for apparent outliers 
\item Lahiri and Larsen (2005):   provides unbiased estimator directly instead of bias correction for OLS, by applying regression to transformed model 
\item Abramitzky, Mill, P\'erez (2019): guide for researchers in the choice of which variables to use for linking, how to estimate probabilities, and then choose which records to use in the analysis.  Created R code and stata command to implement the method
\item Ferrie 1996, Abramitzky, BOustan and Eriksson (2012 2014 2017) are deterministic.  Conservative methods require no other potential match with same name within a 5-year band
\item Semi-automated Feigenbaum, Ruggles et al 
\item Abramitzky, Boustan, Eriksson, Feigenbaum, P\`erez (2019): evaluate different automated methods for record linkage, specifically deterministic (like Ferrie and ABE papers), machine learning Feigenbaum approach, and the AMP approach with the EM algorithm.  Document a frontier between type I and type II errors; cost of low false positive rates comes at cost of designating relatively fewer (true) matches.  Humans typically match more at a cost of more false positives.  They study how different linking methods affect inference -- sensitivity of regression estimates to the choice of linking algorithm.  They find that the parameter estimates are stable across linking methods.  Find effect of matching algorithm on inference is small. 
\item Bailey et al. (2017) say automated methods perform quite poorly
\item Survey paper from handbook of econometrics
\end{itemize}

Overall, high variability in performance of matching methods depending on choice of variables, string comparators used. 


\end{document}